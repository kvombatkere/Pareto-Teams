{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ab02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoKnapsackInfluence import *\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import influence datasets\n",
    "data_path_HEPT = '../../datasets/raw_data/influence/NetHEPT/hep.txt'\n",
    "data_path_PHY = '../../datasets/raw_data/influence/NetPHY/phy.txt'\n",
    "\n",
    "G_HEPT, node_costs_HEPT = import_influence_data(data_path_HEPT)\n",
    "G_PHY, node_costs_PHY = import_influence_data(data_path_PHY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e42466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutionsKnapsackInfluence(G, node_costs, maxBudget, num_samples=35, num_runs=10, dataset_name=\"\"):\n",
    "    '''\n",
    "    Run algorithms over multiple runs and plot mean +/- std (Influence vs Cost + Runtime).\n",
    "    Parameters:\n",
    "    - G: Graph\n",
    "    - node_costs: Node costs dict\n",
    "    - maxBudget: Maximum knapsack budget\n",
    "    - num_samples: Number of Monte Carlo samples per run\n",
    "    - num_runs: Number of independent runs\n",
    "    - dataset_name: Name of the dataset for plotting\n",
    "    '''\n",
    "    # Cost grid (same pattern as teams/restaurants notebooks)\n",
    "    eps, min_cost = 0.1, 1\n",
    "    cost_arr = [min_cost]\n",
    "    while min_cost * (1 + eps) < maxBudget:\n",
    "        min_cost = round(min_cost * (1 + eps), 2)\n",
    "        cost_arr.append(min_cost)\n",
    "    cost_arr.append(maxBudget)\n",
    "    cost_arr = np.array(cost_arr)\n",
    "\n",
    "    algo_names = [\"PlainGreedy\", \"GreedyPlus\", \"TwoGuessPlainGreedy\", \"OneGuessGreedyPlus\", \"PrefixPareto-1Guess\", \"PrefixPareto-2Guess\"]\n",
    "\n",
    "    # containers across runs\n",
    "    all_influences = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        # Generate graph samples once to share across algorithms (per run)\n",
    "        graph_samples = []\n",
    "        for _ in range(num_samples):\n",
    "            G_sample = nx.Graph()\n",
    "            neighbors = defaultdict(set)\n",
    "            connected_components = defaultdict()\n",
    "            for u, v, data in G.edges(data=True):\n",
    "                success = np.random.uniform(0, 1)\n",
    "                if success < data['weight']:\n",
    "                    G_sample.add_edge(u, v)\n",
    "                    neighbors[u].add(v)\n",
    "                    neighbors[v].add(u)\n",
    "            for c in nx.connected_components(G_sample):\n",
    "                for node in c:\n",
    "                    connected_components[node] = c\n",
    "            graph_samples.append((G_sample, neighbors, connected_components))\n",
    "\n",
    "        run_influences = {alg: [] for alg in algo_names}\n",
    "        run_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # Run algorithms over budgets\n",
    "        for budgetVal in cost_arr:\n",
    "            pareto = paretoKnapsackInfluence(G=G,\n",
    "                                             node_costs=node_costs,\n",
    "                                             budget=budgetVal,\n",
    "                                             num_samples=num_samples,\n",
    "                                             graph_samples=graph_samples)\n",
    "\n",
    "            # Plain Greedy\n",
    "            _, infl, cost, runTime = pareto.plainGreedy()\n",
    "            run_influences['PlainGreedy'].append(infl)\n",
    "            run_runtimes['PlainGreedy'].append(runTime)\n",
    "\n",
    "            # Greedy Plus\n",
    "            _, infl, cost, runTime = pareto.greedyPlus()\n",
    "            run_influences['GreedyPlus'].append(infl)\n",
    "            run_runtimes['GreedyPlus'].append(runTime)\n",
    "\n",
    "            # Two Guess Plain Greedy\n",
    "            _, infl, cost, runTime = pareto.twoGuessPlainGreedy()\n",
    "            run_influences['TwoGuessPlainGreedy'].append(infl)\n",
    "            run_runtimes['TwoGuessPlainGreedy'].append(runTime)\n",
    "\n",
    "            # One Guess Greedy Plus\n",
    "            _, infl, cost, runTime = pareto.oneGuessGreedyPlus()\n",
    "            run_influences['OneGuessGreedyPlus'].append(infl)\n",
    "            run_runtimes['OneGuessGreedyPlus'].append(runTime)\n",
    "\n",
    "        # Prefix Pareto (computed once per run at full budget)\n",
    "        pareto_full = paretoKnapsackInfluence(G=G,\n",
    "                                              node_costs=node_costs,\n",
    "                                              budget=maxBudget,\n",
    "                                              num_samples=num_samples,\n",
    "                                              graph_samples=graph_samples)\n",
    "\n",
    "        pp1_costs, pp1_influences, _, pp1_time = pareto_full.prefixParetoGreedy_1Guess()\n",
    "        # pp2_costs, pp2_influences, _, pp2_time = pareto_full.prefixParetoGreedy_2Guess()\n",
    "\n",
    "        # Align prefix pareto curves to cost_arr by interpolation\n",
    "        def align_to_cost_arr(costs, infls):\n",
    "            if len(costs) == 0:\n",
    "                return np.zeros_like(cost_arr, dtype=float)\n",
    "            costs = np.array(costs)\n",
    "            infls = np.array(infls)\n",
    "            return np.interp(cost_arr, costs, infls, left=infls[0], right=infls[-1])\n",
    "\n",
    "        run_influences['PrefixPareto-1Guess'] = list(align_to_cost_arr(pp1_costs, pp1_influences))\n",
    "        # run_influences['PrefixPareto-2Guess'] = list(align_to_cost_arr(pp2_costs, pp2_influences))\n",
    "        run_runtimes['PrefixPareto-1Guess'].append(pp1_time)\n",
    "        # run_runtimes['PrefixPareto-2Guess'].append(pp2_time)\n",
    "\n",
    "        # store per-run arrays and total runtimes\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(run_influences[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(cost_arr, dtype=float)\n",
    "            all_influences[alg].append(arr)\n",
    "            total_runtime = float(np.nansum(np.array(run_runtimes.get(alg, []), dtype=float))) if len(run_runtimes.get(alg, [])) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "    # compute mean and std across runs for each algorithm\n",
    "    mean_influences = {}\n",
    "    std_influences = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_influences[alg])  # shape (num_runs, len(cost_arr))\n",
    "        mean_influences[alg] = np.mean(stacked, axis=0)\n",
    "        std_influences[alg] = np.std(stacked, axis=0) * 0.5\n",
    "\n",
    "    # Plot mean influence with shaded std band\n",
    "    colors = cm.magma(np.linspace(0.01, 0.8, len(algo_names)))\n",
    "    linestyles = ['-', '--', '-.', ':', (0, (3,1,1,1)), (0, (1,1))]\n",
    "    markers = ['o', 's', '^', 'v', 'D', 'X']\n",
    "\n",
    "    plot_order = [a for a in algo_names if not a.startswith('PrefixPareto')] + \\\n",
    "                 [a for a in algo_names if a.startswith('PrefixPareto')]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    for i, alg in enumerate(plot_order):\n",
    "        mean = mean_influences[alg]\n",
    "        std = std_influences[alg]\n",
    "\n",
    "        ax.plot(cost_arr, mean,\n",
    "                label=alg,\n",
    "                color=colors[algo_names.index(alg)],\n",
    "                linestyle=linestyles[i % len(linestyles)],\n",
    "                marker=markers[i % len(markers)],\n",
    "                markersize=5,\n",
    "                markeredgewidth=0.8,\n",
    "                markeredgecolor='k',\n",
    "                linewidth=1.2,\n",
    "                zorder=3)\n",
    "        ax.fill_between(cost_arr,\n",
    "                        np.clip(mean - std, 0, None),\n",
    "                        mean + std,\n",
    "                        color=colors[algo_names.index(alg)],\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_title(f'Mean Influence vs. Cost ({dataset_name}) (shaded = ±0.5 std)')\n",
    "    ax.set_ylabel(\"Mean Influence\")\n",
    "    ax.set_xlabel(\"Cost Budget\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(fontsize=8, ncol=2)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot total runtime per algorithm with mean +/- std bars\n",
    "    means_rt = [np.mean(all_runtimes[alg]) for alg in algo_names]\n",
    "    stds_rt = [np.std(all_runtimes[alg]) for alg in algo_names]\n",
    "    x = np.arange(len(algo_names))\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 3))\n",
    "    bars = ax2.bar(x, means_rt, yerr=stds_rt, capsize=5, color=[colors[i] for i in range(len(algo_names))])\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(algo_names, rotation=30, ha='right', fontsize=8)\n",
    "    ax2.set_ylabel('Total Runtime (s)')\n",
    "    ax2.set_title('Mean Total Runtime per Algorithm (±std)')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return mean_influences, cost_arr, all_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c852fb",
   "metadata": {},
   "source": [
    "### NetHEPT Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "maxBudget = 6\n",
    "num_samples = 10\n",
    "num_runs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run for NetHEPT\n",
    "influences_HEPT, costs_HEPT, runtimes_HEPT = findApproximateParetoSolutionsKnapsackInfluence(\n",
    "    G_HEPT,\n",
    "    node_costs_HEPT,\n",
    "    maxBudget,\n",
    "    num_samples=num_samples,\n",
    "    num_runs=num_runs,\n",
    "    dataset_name=\"NetHEPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f333f9",
   "metadata": {},
   "source": [
    "### NetPHY Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5970864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for NetPHY\n",
    "influences_PHY, costs_PHY, runtimes_PHY = findApproximateParetoSolutionsKnapsackInfluence(\n",
    "    G_PHY,\n",
    "    node_costs_PHY,\n",
    "    maxBudget,\n",
    "    num_samples=num_samples,\n",
    "    num_runs=num_runs,\n",
    "    dataset_name=\"NetPHY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc769a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
