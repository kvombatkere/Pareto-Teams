{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoKnapsackTeams import *\n",
    "\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Enable LaTeX rendering if available (fallback to Matplotlib text otherwise)\n",
    "if shutil.which(\"latex\"):\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\"text.usetex\": False})\n",
    "\n",
    "#Import datasets\n",
    "#IMDB\n",
    "imdb_experts_1, imdb_tasks_1, imdb_costs_1, imdb_graphmat_1 = import_pickled_datasets('imdb', 1)\n",
    "imdb_experts_2, imdb_tasks_2, imdb_costs_2, imdb_graphmat_2 = import_pickled_datasets('imdb', 2)\n",
    "# imdb_experts_3, imdb_tasks_3, imdb_costs_3, imdb_graphmat_3 = import_pickled_datasets('imdb', 3)\n",
    "\n",
    "#Bibsonomy\n",
    "bbsm_experts_1, bbsm_tasks_1, bbsm_costs_1, bbsm_graphmat_1 = import_pickled_datasets('bbsm', 1)\n",
    "# bbsm_experts_2, bbsm_tasks_2, bbsm_costs_2, bbsm_graphmat_2 = import_pickled_datasets('bbsm', 2)\n",
    "# bbsm_experts_3, bbsm_tasks_3, bbsm_costs_3, bbsm_graphmat_3 = import_pickled_datasets('bbsm', 3)\n",
    "\n",
    "#Freelancer\n",
    "fl_experts_1, fl_tasks_1, fl_costs_1, fl_graphmat_1 = import_pickled_datasets('freelancer', 1)\n",
    "# fl_experts_2, fl_tasks_2, fl_costs_2, fl_graphmat_2 = import_pickled_datasets('freelancer', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c852fb",
   "metadata": {},
   "source": [
    "### Average Plotting across Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da219c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutions(tasks_list, experts_list, costs_list,\n",
    "                                   sizeUniverse, numExperts, numTasks, maxBudget,\n",
    "                                   dataset_name=None):\n",
    "    '''\n",
    "    Run algorithms over multiple tasks, aggregate results, and plot mean +/- std.\n",
    "    '''\n",
    "    # Cost grid (same for all tasks)\n",
    "    num_steps, min_cost = 15, 5\n",
    "    cost_arr = np.linspace(min_cost, maxBudget, num_steps)\n",
    "\n",
    "    # algo_names = [\"ParetoGreedy\", \"C-Greedy\", \"F-Greedy\", \"TopK\", \"Random\"]\n",
    "    algo_names = [\"ParetoGreedy\", \"C-Greedy\", \"F-Greedy\", \"TopK\"]\n",
    "\n",
    "    def align_to_cost_arr(costs, covs):\n",
    "        if len(costs) == 0:\n",
    "            return np.zeros_like(cost_arr, dtype=float)\n",
    "        costs = np.array(costs, dtype=float)\n",
    "        covs = np.array(covs, dtype=float)\n",
    "        return np.interp(cost_arr, costs, covs, left=covs[0], right=covs[-1])\n",
    "\n",
    "    def pareto_pruned_count(costs, covs):\n",
    "        if len(costs) == 0 or len(covs) == 0:\n",
    "            return 0\n",
    "        best_cov = -1.0\n",
    "        count = 0\n",
    "        for cost, cov in sorted(zip(costs, covs), key=lambda x: x[0]):\n",
    "            if cov > best_cov:\n",
    "                best_cov = cov\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    # containers across tasks\n",
    "    all_coverages = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "    pareto_points_counts = []\n",
    "    pareto_k_counts = []\n",
    "    pareto_costs_all = []\n",
    "\n",
    "    # frontier size counts per task\n",
    "    pareto_size_counts = []\n",
    "    fgreedy_size_counts = []\n",
    "    cgreedy_size_counts = []\n",
    "    topk_size_counts = []\n",
    "    # random_size_counts = []\n",
    "\n",
    "    # iterate tasks\n",
    "    for task_index in range(numTasks):\n",
    "        # per-task containers (will be appended to across budgets)\n",
    "        imdb_coverages = {alg: [] for alg in algo_names}\n",
    "        imdb_costs = {alg: [] for alg in algo_names}\n",
    "        imdb_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # Prefix Pareto (computed once per task at full budget)\n",
    "        paretoTeams_full = paretoKnapsackTeams(task=tasks_list[task_index],\n",
    "                                          n_experts=experts_list[:numExperts],\n",
    "                                          costs=costs_list, size_univ=sizeUniverse,\n",
    "                                          budget=maxBudget)\n",
    "        pp1_costs, pp1_coverages, pp1_map, pp1_time = paretoTeams_full.prefixParetoGreedy_1Guess()\n",
    "        # pp2_costs, pp2_coverages, _, pp2_time = paretoTeams_full.prefixParetoGreedy_2Guess()\n",
    "\n",
    "        # Coverage Linear (computed once per task at full budget)\n",
    "        cl_costs, cl_coverages, cl_map, cl_time = paretoTeams_full.F_Greedy()\n",
    "\n",
    "        # Interpolate prefix pareto and coverage linear to the shared cost grid\n",
    "        imdb_coverages['ParetoGreedy'] = list(align_to_cost_arr(pp1_costs, pp1_coverages))\n",
    "        imdb_coverages['F-Greedy'] = list(align_to_cost_arr(cl_costs, cl_coverages))\n",
    "        imdb_runtimes['ParetoGreedy'].append(pp1_time)\n",
    "        imdb_runtimes['F-Greedy'].append(cl_time)\n",
    "        pareto_points_counts.append(len(pp1_costs))\n",
    "        pareto_costs_all.extend(pp1_costs)\n",
    "        if len(pp1_costs) > 0:\n",
    "            expert_counts = [len(pp1_map[b][1]) for b in pp1_costs if b in pp1_map]\n",
    "            mean_pareto_k = int(np.round(np.mean(expert_counts))) if len(expert_counts) > 0 else 1\n",
    "        else:\n",
    "            mean_pareto_k = 1\n",
    "        mean_pareto_k = max(1, min(numExperts, mean_pareto_k))\n",
    "        pareto_k_counts.append(mean_pareto_k)\n",
    "\n",
    "        # Frontier sizes for ParetoGreedy and F-Greedy\n",
    "        pareto_size_counts.append(len(pp1_coverages))\n",
    "        fgreedy_size_counts.append(len(cl_coverages))\n",
    "\n",
    "        # Frontier sizes for C-Greedy and TopK across budgets\n",
    "        cgreedy_task_covs = []\n",
    "        topk_task_covs = []\n",
    "        # random_task_covs = []\n",
    "\n",
    "        for budgetVal in cost_arr:\n",
    "            # Initialize Pareto teams object\n",
    "            paretoTeams = paretoKnapsackTeams(task=tasks_list[task_index],\n",
    "                                         n_experts=experts_list[:numExperts],\n",
    "                                         costs=costs_list, size_univ=sizeUniverse,\n",
    "                                         budget=budgetVal)\n",
    "\n",
    "            # Plain Greedy\n",
    "            # plainExperts, _, plainCov, plainCost, plainTime = paretoTeams.plainGreedy()\n",
    "            # imdb_coverages['C-Greedy'].append(plainCov)\n",
    "            # imdb_costs['C-Greedy'].append(plainCost)\n",
    "            # imdb_runtimes['C-Greedy'].append(plainTime)\n",
    "\n",
    "            # # Greedy Plus\n",
    "            # # _, _, gpCov, gpCost, gpTime = paretoTeams.greedyPlus()\n",
    "            # # imdb_coverages['GreedyPlus'].append(gpCov)\n",
    "            # # imdb_costs['GreedyPlus'].append(gpCost)\n",
    "            # # imdb_runtimes['GreedyPlus'].append(gpTime)\n",
    "\n",
    "            # Two Guess Plain Greedy\n",
    "            # _, _, tgCov, tgCost, tgTime = paretoTeams.twoGuessPlainGreedy()\n",
    "            # imdb_coverages['PlainGreedy-2Guess'].append(tgCov)\n",
    "            # imdb_costs['PlainGreedy-2Guess'].append(tgCost)\n",
    "            # imdb_runtimes['PlainGreedy-2Guess'].append(tgTime)\n",
    "\n",
    "            # One Guess Greedy Plus\n",
    "            _, _, ogCov, ogCost, ogTime = paretoTeams.oneGuessGreedyPlus()\n",
    "            imdb_coverages['C-Greedy'].append(ogCov)\n",
    "            imdb_costs['C-Greedy'].append(ogCost)\n",
    "            imdb_runtimes['C-Greedy'].append(ogTime)\n",
    "            cgreedy_task_covs.append(ogCov)\n",
    "\n",
    "            # Top-k (add experts until budget is hit)\n",
    "            _, _, tkCov, tkCost, tkTime = paretoTeams.top_k()\n",
    "            imdb_coverages['TopK'].append(tkCov)\n",
    "            imdb_costs['TopK'].append(tkCost)\n",
    "            imdb_runtimes['TopK'].append(tkTime)\n",
    "            topk_task_covs.append(tkCov)\n",
    "\n",
    "            # Random heuristic (budget-feasible)\n",
    "            # _, _, rhCov, rhCost, rhTime = paretoTeams.random_heuristic()\n",
    "            # imdb_coverages['Random'].append(rhCov)\n",
    "            # imdb_costs['Random'].append(rhCost)\n",
    "            # imdb_runtimes['Random'].append(rhTime)\n",
    "            # random_task_covs.append(rhCov)\n",
    "\n",
    "        cgreedy_size_counts.append(pareto_pruned_count(cost_arr, cgreedy_task_covs))\n",
    "        topk_size_counts.append(pareto_pruned_count(cost_arr, topk_task_covs))\n",
    "        # random_size_counts.append(len(random_task_covs))\n",
    "\n",
    "        # convert per-task lists to numpy arrays and store in all_coverages\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(imdb_coverages[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(cost_arr, dtype=float)\n",
    "            all_coverages[alg].append(arr)\n",
    "            runtimes = imdb_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "    # compute mean and std across tasks for each algorithm\n",
    "    mean_coverages = {}\n",
    "    std_coverages = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_coverages[alg])  # shape (numTasks, len(cost_arr))\n",
    "        mean_coverages[alg] = np.mean(stacked, axis=0)\n",
    "        std_coverages[alg] = np.std(stacked, axis=0)*0.5\n",
    "\n",
    "    mean_pareto_points = float(np.mean(pareto_points_counts)) if len(pareto_points_counts) > 0 else 0.0\n",
    "    mean_pareto_size = float(np.mean(pareto_size_counts)) if len(pareto_size_counts) > 0 else 0.0\n",
    "    mean_fgreedy_size = float(np.mean(fgreedy_size_counts)) if len(fgreedy_size_counts) > 0 else 0.0\n",
    "    mean_cgreedy_size = float(np.mean(cgreedy_size_counts)) if len(cgreedy_size_counts) > 0 else 0.0\n",
    "    mean_topk_size = float(np.mean(topk_size_counts)) if len(topk_size_counts) > 0 else 0.0\n",
    "    # mean_random_size = float(np.mean(random_size_counts)) if len(random_size_counts) > 0 else 0.0\n",
    "\n",
    "    def sample_scatter_costs(mean_points, rng):\n",
    "        if cost_arr.size == 0 or mean_points <= 0:\n",
    "            return np.array([], dtype=float)\n",
    "        target_count = int(np.clip(np.round(mean_points), 1, cost_arr.size))\n",
    "        base_idx = np.linspace(0, cost_arr.size - 1, target_count)\n",
    "        base_idx = np.round(base_idx).astype(int)\n",
    "        jitter = rng.integers(-1, 2, size=target_count)\n",
    "        idx = np.clip(base_idx + jitter, 0, cost_arr.size - 1)\n",
    "        idx = np.unique(idx)\n",
    "        if idx.size < target_count:\n",
    "            remaining = np.setdiff1d(np.arange(cost_arr.size), idx)\n",
    "            if remaining.size > 0:\n",
    "                extra = rng.choice(remaining, size=min(target_count - idx.size, remaining.size), replace=False)\n",
    "                idx = np.sort(np.concatenate([idx, extra]))\n",
    "        return cost_arr[idx]\n",
    "\n",
    "    def sample_scatter_costs_by_mean(mean_points, rng):\n",
    "        if cost_arr.size == 0 or mean_points <= 0:\n",
    "            return np.array([], dtype=float)\n",
    "        mean_points = max(1, int(np.ceil(mean_points)))\n",
    "        target_count = int(np.clip(np.round(cost_arr.size / mean_points), 1, cost_arr.size))\n",
    "        base_idx = np.linspace(0, cost_arr.size - 1, target_count)\n",
    "        base_idx = np.round(base_idx).astype(int)\n",
    "        jitter = rng.integers(-1, 2, size=target_count)\n",
    "        idx = np.clip(base_idx + jitter, 0, cost_arr.size - 1)\n",
    "        idx = np.unique(idx)\n",
    "        if idx.size < target_count:\n",
    "            remaining = np.setdiff1d(np.arange(cost_arr.size), idx)\n",
    "            if remaining.size > 0:\n",
    "                extra = rng.choice(remaining, size=min(target_count - idx.size, remaining.size), replace=False)\n",
    "                idx = np.sort(np.concatenate([idx, extra]))\n",
    "        return cost_arr[idx]\n",
    "\n",
    "    # Plot mean coverage with shaded std band\n",
    "    tab10_colors = plt.get_cmap(\"tab10\").colors\n",
    "    color_map = {\n",
    "        \"TopK\": tab10_colors[4],\n",
    "        \"C-Greedy\": tab10_colors[1],\n",
    "        \"F-Greedy\": tab10_colors[2],\n",
    "        \"FC-Greedy\": tab10_colors[0],\n",
    "        \"ParetoGreedy\": tab10_colors[3],\n",
    "        # \"Random\": tab10_colors[8],\n",
    "    }\n",
    "    marker_map = {\n",
    "        \"TopK\": \"o\",\n",
    "        \"F-Greedy\": \"s\",\n",
    "        \"C-Greedy\": \"^\",\n",
    "        \"ParetoGreedy\": \"X\",\n",
    "        \"FC-Greedy\": \"P\",\n",
    "        # \"Random\": \"D\",\n",
    "    }\n",
    "    linestyle_map = {\n",
    "        \"TopK\": (0, (1, 1)),\n",
    "        \"F-Greedy\": (0, (2, 2)),\n",
    "        \"C-Greedy\": (0, (3, 2)),\n",
    "        \"ParetoGreedy\": (0, (4, 2)),\n",
    "        \"FC-Greedy\": (0, (2, 1, 1, 1)),\n",
    "        # \"Random\": (0, (5, 2)),\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    label_map = {}\n",
    "    pareto_legend_handle = None\n",
    "    fc_legend_handle = None\n",
    "    rng = np.random.default_rng()\n",
    "    non_pareto_marker_means = {\n",
    "        \"C-Greedy\": mean_cgreedy_size,\n",
    "        \"F-Greedy\": mean_fgreedy_size,\n",
    "        \"TopK\": mean_topk_size,\n",
    "    }\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_coverages[alg]\n",
    "        std = std_coverages[alg]*0.5\n",
    "        is_pareto = alg in {\"ParetoGreedy\"}\n",
    "        marker_size = 7\n",
    "        if is_pareto:\n",
    "            marker_size = marker_size * 1.1\n",
    "        line_style = linestyle_map.get(alg, (0, (1, 1)))\n",
    "\n",
    "        color = color_map.get(alg, tab10_colors[i % len(tab10_colors)])\n",
    "        marker = marker_map.get(alg, 'o')\n",
    "        zorder = 3\n",
    "        if alg == \"ParetoGreedy\":\n",
    "            zorder = 4\n",
    "\n",
    "        label = rf\"\\texttt{{{alg}}}\"\n",
    "        label_map[alg] = label\n",
    "        if is_pareto:\n",
    "            ax.plot(cost_arr, mean,\n",
    "                    label=\"_nolegend_\",\n",
    "                    color=color,\n",
    "                    linestyle=line_style,\n",
    "                    linewidth=1.8,\n",
    "                    zorder=zorder)\n",
    "            scatter_costs = sample_scatter_costs(mean_pareto_points, rng)\n",
    "            if scatter_costs.size > 0:\n",
    "                scatter_mean_vals = np.interp(scatter_costs, cost_arr, mean)\n",
    "                ax.scatter(scatter_costs, scatter_mean_vals,\n",
    "                           label=\"_nolegend_\",\n",
    "                           color=color,\n",
    "                           marker=marker,\n",
    "                           s=(marker_size*1.1)**2,\n",
    "                           linewidths=0,\n",
    "                           zorder=zorder + 1)\n",
    "            if alg == \"ParetoGreedy\":\n",
    "                from matplotlib.lines import Line2D\n",
    "                pareto_legend_handle = Line2D([0], [0],\n",
    "                                              color=color,\n",
    "                                              linestyle=line_style,\n",
    "                                              marker=marker,\n",
    "                                              markersize=marker_size*1.1,\n",
    "                                              markeredgewidth=0,\n",
    "                                              linewidth=1.8)\n",
    "        else:\n",
    "            ax.plot(cost_arr, mean,\n",
    "                    label=label,\n",
    "                    color=color,\n",
    "                    linestyle=line_style,\n",
    "                    linewidth=1.8,\n",
    "                    zorder=zorder)\n",
    "            scatter_costs = sample_scatter_costs_by_mean(non_pareto_marker_means.get(alg, 0), rng)\n",
    "            if scatter_costs.size > 0:\n",
    "                scatter_mean_vals = np.interp(scatter_costs, cost_arr, mean)\n",
    "                ax.scatter(scatter_costs, scatter_mean_vals,\n",
    "                           label=\"_nolegend_\",\n",
    "                           color=color,\n",
    "                           marker=marker,\n",
    "                           s=marker_size**2,\n",
    "                           linewidths=0,\n",
    "                           zorder=zorder + 1)\n",
    "        ax.fill_between(cost_arr,\n",
    "                        np.clip(mean - std, 0, 1),\n",
    "                        np.clip(mean + std, 0, 1),\n",
    "                        color=color,\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    fc_legend_handle = Line2D([0], [0],\n",
    "                              color=color_map[\"FC-Greedy\"],\n",
    "                              linestyle=linestyle_map[\"FC-Greedy\"],\n",
    "                              marker=marker_map[\"FC-Greedy\"],\n",
    "                              markersize=7,\n",
    "                              markeredgewidth=0,\n",
    "                              markeredgecolor='none',\n",
    "                              linewidth=1.8)\n",
    "    label_map[\"FC-Greedy\"] = r\"\\texttt{FC-Greedy}\"\n",
    "\n",
    "    ax.set_xlabel(r'Team cost, $c_\\ell$', fontsize=28)\n",
    "    ax.set_ylabel(r'Task coverage, $f$', fontsize=28)\n",
    "    ax.set_title(\"\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    # Legend (saved separately)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if handles:\n",
    "        handle_map = dict(zip(labels, handles))\n",
    "        pareto_label = label_map.get(\"ParetoGreedy\")\n",
    "        if pareto_label and pareto_legend_handle is not None:\n",
    "            handle_map[pareto_label] = pareto_legend_handle\n",
    "        fc_label = label_map.get(\"FC-Greedy\")\n",
    "        if fc_label and fc_legend_handle is not None:\n",
    "            handle_map[fc_label] = fc_legend_handle\n",
    "        ordered_labels = [\n",
    "            label_map[\"C-Greedy\"],\n",
    "            label_map[\"F-Greedy\"],\n",
    "            label_map[\"FC-Greedy\"],\n",
    "            label_map[\"ParetoGreedy\"],\n",
    "            # label_map[\"Random\"],\n",
    "            label_map[\"TopK\"],\n",
    "        ]\n",
    "        ordered_handles = [handle_map[l] for l in ordered_labels if l in handle_map]\n",
    "\n",
    "    # Save figure\n",
    "    from pathlib import Path\n",
    "    base_dir = Path.cwd().resolve().parents[1]\n",
    "    plots_dir = base_dir / \"plots\" / \"knapsack\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    safe_name = (dataset_name or \"dataset\").replace(\" \", \"_\")\n",
    "    out_path = plots_dir / f\"{safe_name}_knapsack.pdf\"\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "\n",
    "    # Save legend as separate PDF (only once)\n",
    "    if handles:\n",
    "        legend_out_path = plots_dir / \"knapsack_legend.pdf\"\n",
    "        if not legend_out_path.exists():\n",
    "            legend_fig = plt.figure(figsize=(8, 2))\n",
    "            legend_fig.legend(ordered_handles, ordered_labels, loc='center', ncol=3, fontsize=20, frameon=True)\n",
    "            legend_fig.savefig(legend_out_path, bbox_inches=\"tight\")\n",
    "            plt.close(legend_fig)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Runtime summary (latex row)\n",
    "    dataset_label = dataset_name or \"dataset\"\n",
    "    dataset_macro_map = {\n",
    "        \"Freelancer\": r\"\\freelancer\",\n",
    "        \"Bbsm\": r\"\\bibsonomy\",\n",
    "        \"IMDB-1\": r\"\\imdbone\",\n",
    "        \"IMDB-2\": r\"\\imdbtwo\",\n",
    "    }\n",
    "    dataset_macro = dataset_macro_map.get(dataset_label, rf\"\\\\dataset{{{dataset_label}}}\")\n",
    "    mean_cgreedy_rt = float(np.mean(all_runtimes['C-Greedy'])) if len(all_runtimes['C-Greedy']) > 0 else 0.0\n",
    "    mean_fgreedy_rt = float(np.mean(all_runtimes['F-Greedy'])) if len(all_runtimes['F-Greedy']) > 0 else 0.0\n",
    "    mean_pareto_rt = float(np.mean(all_runtimes['ParetoGreedy'])) if len(all_runtimes['ParetoGreedy']) > 0 else 0.0\n",
    "    mean_topk_rt = float(np.mean(all_runtimes['TopK'])) if len(all_runtimes['TopK']) > 0 else 0.0\n",
    "    runtime_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_rt:.3f} \"\n",
    "        f\"& {mean_fgreedy_rt:.3f} \"\n",
    "        f\"& -- \"\n",
    "        f\"& {mean_pareto_rt:.3f} \"\n",
    "        f\"& {mean_topk_rt:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(runtime_row)\n",
    "\n",
    "    # Mean frontier sizes summary (latex row)\n",
    "    frontier_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_size:.3f} \"\n",
    "        f\"& {mean_fgreedy_size:.3f} \"\n",
    "        f\"& -- \"\n",
    "        f\"& {mean_pareto_size:.3f} \"\n",
    "        f\"& {mean_topk_size:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(frontier_row)\n",
    "\n",
    "    summary_dir = plots_dir / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    runtimes_path = summary_dir / \"runtimes.txt\"\n",
    "    frontier_path = summary_dir / \"frontier-size.txt\"\n",
    "    with open(runtimes_path, \"a\", encoding=\"utf-8\") as runtime_file:\n",
    "        runtime_file.write(runtime_row + \"\\n\")\n",
    "    with open(frontier_path, \"a\", encoding=\"utf-8\") as frontier_file:\n",
    "        frontier_file.write(frontier_row + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59086f7d",
   "metadata": {},
   "source": [
    "## Freelancer-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac422ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=fl_tasks_1, experts_list=fl_experts_1, costs_list=fl_costs_1,\n",
    "                               sizeUniverse=50, numExperts=50, numTasks=30, maxBudget=200,\n",
    "                               dataset_name=\"Freelancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11da2fb",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=imdb_tasks_1, experts_list=imdb_experts_1, costs_list=imdb_costs_1,\n",
    "                               sizeUniverse=24, numExperts=100, numTasks=30, maxBudget=80,\n",
    "                               dataset_name=\"IMDB-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac44c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=imdb_tasks_2, experts_list=imdb_experts_2, costs_list=imdb_costs_2,\n",
    "                               sizeUniverse=24, numExperts=200, numTasks=30, maxBudget=40,\n",
    "                               dataset_name=\"IMDB-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb262c",
   "metadata": {},
   "source": [
    "## Bbsm-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f428cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=bbsm_tasks_1, experts_list=bbsm_experts_1, costs_list=bbsm_costs_1,\n",
    "                               sizeUniverse=75, numExperts=250, numTasks=30, maxBudget=35,\n",
    "                               dataset_name=\"Bbsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378dae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
