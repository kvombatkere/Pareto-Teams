{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoKnapsackRestaurants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to sample numItems from the dataset\n",
    "def sample_dataset(simMatrix, item_ids, item_costs, numItems):\n",
    "    '''\n",
    "    Samples a subset of items from the dataset.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.\n",
    "        item_costs (list): List of item costs of length N.\n",
    "        numItems (int): Number of items to sample.\n",
    "    Returns:\n",
    "        sampled_simMatrix (np.ndarray): Sampled similarity matrix of shape (numItems, numItems).\n",
    "        sampled_item_ids (list): List of sampled item IDs of length numItems.\n",
    "        sampled_item_costs (list): List of sampled item costs of length numItems.\n",
    "    '''\n",
    "    sampled_indices = np.random.choice(len(item_ids), size=numItems, replace=False)\n",
    "    sampled_simMatrix = simMatrix[np.ix_(sampled_indices, sampled_indices)]\n",
    "    sampled_item_ids = [item_ids[i] for i in sampled_indices]\n",
    "    sampled_item_costs = [item_costs[i] for i in sampled_indices]\n",
    "\n",
    "    return sampled_simMatrix, sampled_item_ids, sampled_item_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sample dataset\n",
    "# numItems = 100 \n",
    "# phoenix_simMatrix_sample, phoenix_ids_sample, phoenix_costs_sample = sample_dataset(phoenix_simMatrix, phoenix_ids, phoenix_costs, numItems)\n",
    "\n",
    "# paretoPhoenix = paretoKnapsackRestaurants(n_items=phoenix_ids_sample,\n",
    "#                                           costs=phoenix_costs_sample,\n",
    "#                                           simMatrix=phoenix_simMatrix_sample,\n",
    "#                                           budget=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52d5f9",
   "metadata": {},
   "source": [
    "### Yelp - Average plotting across different random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutions(simMatrix, item_ids, item_costs, sample_size, numSamples, maxBudget):\n",
    "    '''\n",
    "    Run algorithms over multiple random samples of the dataset, aggregate results, and plot mean +/- std.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.      \n",
    "        item_costs (list): List of item costs of length N.\n",
    "        sample_size (int): Number of items to sample from the dataset.\n",
    "        numSamples (int): Number of random samples to run.\n",
    "        maxBudget (float): Maximum budget for the knapsack problem.\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    # Cost grid (same for all samples)\n",
    "    eps, min_cost = 0.1, 1\n",
    "    cost_arr = [min_cost]\n",
    "    while min_cost*(1+eps) < maxBudget:\n",
    "        min_cost = round(min_cost*(1 + eps), 2)\n",
    "        cost_arr.append(min_cost)\n",
    "    cost_arr.append(maxBudget)\n",
    "    cost_arr = np.array(cost_arr)\n",
    "\n",
    "    algo_names = [\"PlainGreedy\", \"GreedyPlus\", \"TwoGuessPlainGreedy\", \"OneGuessGreedyPlus\", \"PrefixPareto-1Guess\", \"PrefixPareto-2Guess\"]\n",
    "\n",
    "    # containers across samples\n",
    "    all_objectives = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "    print(f\"Starting processing {numSamples} samples with sample size {sample_size} and max budget {maxBudget}\")\n",
    "\n",
    "    # iterate samples\n",
    "    for sample_index in range(numSamples):\n",
    "        print(f\"Processing sample {sample_index + 1}/{numSamples}\")\n",
    "        \n",
    "        # per-sample containers (will be appended to across budgets)\n",
    "        sample_objectives = {alg: [] for alg in algo_names}\n",
    "        sample_costs = {alg: [] for alg in algo_names}\n",
    "        sample_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # sample the dataset\n",
    "        sampled_simMatrix, sampled_item_ids, sampled_item_costs = sample_dataset(simMatrix, item_ids, item_costs, sample_size)\n",
    "\n",
    "        for budgetVal in cost_arr:\n",
    "            # Initialize Pareto restaurants object\n",
    "            paretoRest = paretoKnapsackRestaurants(n_items=sampled_item_ids,\n",
    "                                                   costs=sampled_item_costs,\n",
    "                                                   simMatrix=sampled_simMatrix,\n",
    "                                                   budget=budgetVal)\n",
    "\n",
    "            # Plain Greedy\n",
    "            _, curr_objective, curr_cost, runTime = paretoRest.plainGreedy()\n",
    "            sample_objectives['PlainGreedy'].append(curr_objective)\n",
    "            sample_costs['PlainGreedy'].append(curr_cost)\n",
    "            sample_runtimes['PlainGreedy'].append(runTime)\n",
    "\n",
    "            # Greedy Plus\n",
    "            _, curr_objective, curr_cost, runTime = paretoRest.greedyPlus()\n",
    "            sample_objectives['GreedyPlus'].append(curr_objective)\n",
    "            sample_costs['GreedyPlus'].append(curr_cost)\n",
    "            sample_runtimes['GreedyPlus'].append(runTime)\n",
    "\n",
    "            # Two Guess Plain Greedy\n",
    "            _, curr_objective, curr_cost, runTime = paretoRest.twoGuessPlainGreedy()\n",
    "            sample_objectives['TwoGuessPlainGreedy'].append(curr_objective)\n",
    "            sample_costs['TwoGuessPlainGreedy'].append(curr_cost)\n",
    "            sample_runtimes['TwoGuessPlainGreedy'].append(runTime)\n",
    "\n",
    "            # One Guess Greedy Plus\n",
    "            _, curr_objective, curr_cost, runTime = paretoRest.oneGuessGreedyPlus()\n",
    "            sample_objectives['OneGuessGreedyPlus'].append(curr_objective)\n",
    "            sample_costs['OneGuessGreedyPlus'].append(curr_cost)\n",
    "            sample_runtimes['OneGuessGreedyPlus'].append(runTime)\n",
    "\n",
    "        # Prefix Pareto (computed once per sample at full budget)\n",
    "        print(f\"  Running PrefixPareto algorithms for sample {sample_index + 1}\")\n",
    "        paretoRest_full = paretoKnapsackRestaurants(n_items=sampled_item_ids,\n",
    "                                                    costs=sampled_item_costs,\n",
    "                                                    simMatrix=sampled_simMatrix,\n",
    "                                                    budget=maxBudget)\n",
    "        pp1_costs, pp1_objectives, _, pp1_time = paretoRest_full.prefixParetoGreedy_1Guess()\n",
    "        pp2_costs, pp2_objectives, _, pp2_time = paretoRest_full.prefixParetoGreedy_2Guess()\n",
    "\n",
    "        # Ensure prefix pareto objectives align with the cost_arr length if possible.\n",
    "        # We'll resample/pad to cost_arr length: simplest is to interpolate by cost.\n",
    "        def align_to_cost_arr(costs, objs):\n",
    "            if len(costs) == 0:\n",
    "                return np.zeros_like(cost_arr, dtype=float)\n",
    "            costs = np.array(costs)\n",
    "            objs = np.array(objs)\n",
    "            # if cost objective mapping is strictly increasing in costs, we can interpolate\n",
    "            return np.interp(cost_arr, costs, objs, left=objs[0], right=objs[-1])\n",
    "\n",
    "        sample_objectives['PrefixPareto-1Guess'] = list(align_to_cost_arr(pp1_costs, pp1_objectives))\n",
    "        sample_objectives['PrefixPareto-2Guess'] = list(align_to_cost_arr(pp2_costs, pp2_objectives))\n",
    "        sample_runtimes['PrefixPareto-1Guess'].append(pp1_time)\n",
    "        sample_runtimes['PrefixPareto-2Guess'].append(pp2_time)\n",
    "\n",
    "        # # Min-max normalize objectives per algorithm for comparability across samples\n",
    "        # for alg in algo_names:\n",
    "        #     objs = sample_objectives[alg]\n",
    "        #     if objs:\n",
    "        #         min_obj = min(objs)\n",
    "        #         max_obj = max(objs)\n",
    "        #         if max_obj > min_obj:\n",
    "        #             sample_objectives[alg] = [(obj - min_obj) / (max_obj - min_obj) for obj in objs]\n",
    "        #         else:\n",
    "        #             sample_objectives[alg] = [0.0 for _ in objs]  # All same, set to 0\n",
    "\n",
    "        # convert per-sample lists to numpy arrays and store in all_objectives\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(sample_objectives[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(cost_arr, dtype=float)\n",
    "            all_objectives[alg].append(arr)\n",
    "            # store total runtime per sample (sum over budgets or single value for prefix)\n",
    "            runtimes = sample_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "        print(f\"Completed sample {sample_index + 1}\")\n",
    "\n",
    "    print(\"All samples processed, computing statistics and plotting\")\n",
    "\n",
    "    # compute mean and std across samples for each algorithm\n",
    "    mean_objectives = {}\n",
    "    std_objectives = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_objectives[alg])  # shape (numSamples, len(cost_arr))\n",
    "        mean_objectives[alg] = np.mean(stacked, axis=0)\n",
    "        std_objectives[alg] = np.std(stacked, axis=0) * 0.5\n",
    "\n",
    "    # Plot mean objective with shaded std band\n",
    "    # plotting: distinct linestyles + markers; plot prefix pareto last & bolder\n",
    "    colors = cm.magma(np.linspace(0.01, 0.8, len(algo_names)))\n",
    "    linestyles = ['--', '--', '--', '--', '-', '-']  # dashed for baselines, solid for PrefixPareto\n",
    "    markers = ['o', 's', '^', 'v', 'D', 'X']\n",
    "    markersizes = [3, 3, 3, 3, 5, 5]  # smaller for baselines, larger for PrefixPareto\n",
    "\n",
    "    # ensure PrefixPareto lines plotted last\n",
    "    plot_order = [a for a in algo_names if not a.startswith('PrefixPareto')] + \\\n",
    "                 [a for a in algo_names if a.startswith('PrefixPareto')]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    for i, alg in enumerate(plot_order):\n",
    "        mean = mean_objectives[alg]\n",
    "        std = std_objectives[alg]\n",
    "\n",
    "        ax.plot(cost_arr, mean,\n",
    "                label=alg,\n",
    "                color=colors[algo_names.index(alg)],\n",
    "                linestyle=linestyles[algo_names.index(alg)],\n",
    "                marker=markers[algo_names.index(alg)],\n",
    "                markersize=markersizes[algo_names.index(alg)],\n",
    "                markeredgewidth=0.8,\n",
    "                markeredgecolor='k',\n",
    "                linewidth=1.2,\n",
    "                zorder=3)\n",
    "        ax.fill_between(cost_arr,\n",
    "                        np.clip(mean - std, 0, None),  # assuming objectives >=0\n",
    "                        mean + std,\n",
    "                        color=colors[algo_names.index(alg)],\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel('Cost')\n",
    "    ax.set_ylabel('Mean Objective Value')\n",
    "    ax.set_title('Mean Objective across samples (shaded = ±0.5 std)')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(fontsize=8, ncol=2)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot total runtime per algorithm with mean +/- std bars\n",
    "    means_rt = [np.mean(all_runtimes[alg]) for alg in algo_names]\n",
    "    stds_rt = [np.std(all_runtimes[alg]) for alg in algo_names]\n",
    "    x = np.arange(len(algo_names))\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 3))\n",
    "    bars = ax2.bar(x, means_rt, yerr=stds_rt, capsize=5, color=[colors[i] for i in range(len(algo_names))])\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(algo_names, rotation=30, ha='right', fontsize=8)\n",
    "    ax2.set_ylabel('Total Runtime (s)')\n",
    "    ax2.set_title('Mean Total Runtime per Algorithm (±std)')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Plotting completed\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa65a09",
   "metadata": {},
   "source": [
    "### Yelp Phoenix Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Yelp dataset\n",
    "data_path = 'datasets/pickled_data/yelp/yelp_phoenix_'\n",
    "    \n",
    "#Import pickled data\n",
    "with open(data_path + 'ids.pkl', \"rb\") as fp:\n",
    "    phoenix_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'sim.pkl', \"rb\") as fp:\n",
    "    phoenix_simMatrix = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'costs.pkl', \"rb\") as fp:\n",
    "    phoenix_costs = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call findApproximateParetoSolutions (adjust parameters as needed)\n",
    "sample_size = 50\n",
    "numSamples = 5  # e.g., number of random samples\n",
    "maxBudget = 30\n",
    "\n",
    "findApproximateParetoSolutions(phoenix_simMatrix, phoenix_ids, phoenix_costs, sample_size, numSamples, maxBudget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4abbb1",
   "metadata": {},
   "source": [
    "### Yelp Vegas Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c47324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Vegas dataset\n",
    "data_path = 'datasets/pickled_data/yelp/yelp_vegas_' \n",
    "\n",
    "#Import pickled data\n",
    "with open(data_path + 'ids.pkl', \"rb\") as fp:\n",
    "    vegas_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'sim.pkl', \"rb\") as fp:\n",
    "    vegas_simMatrix = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'costs.pkl', \"rb\") as fp:\n",
    "    vegas_costs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call findApproximateParetoSolutions (adjust parameters as needed)\n",
    "sample_size = 50\n",
    "numSamples = 5  # e.g., number of random samples\n",
    "maxBudget = 30\n",
    "\n",
    "findApproximateParetoSolutions(vegas_simMatrix, vegas_ids, vegas_costs, sample_size, numSamples, maxBudget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123730aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
