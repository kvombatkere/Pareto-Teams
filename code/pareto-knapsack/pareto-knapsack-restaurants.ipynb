{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoKnapsackRestaurants import *\n",
    "\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Enable LaTeX rendering if available (fallback to Matplotlib text otherwise)\n",
    "if shutil.which(\"latex\"):\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\"text.usetex\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to sample numItems from the dataset\n",
    "def sample_dataset(simMatrix, item_ids, item_costs, numItems):\n",
    "    '''\n",
    "    Samples a subset of items from the dataset.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.\n",
    "        item_costs (list): List of item costs of length N.\n",
    "        numItems (int): Number of items to sample.\n",
    "    Returns:\n",
    "        sampled_simMatrix (np.ndarray): Sampled similarity matrix of shape (numItems, numItems).\n",
    "        sampled_item_ids (list): List of sampled item IDs of length numItems.\n",
    "        sampled_item_costs (list): List of sampled item costs of length numItems.\n",
    "    '''\n",
    "    sampled_indices = np.random.choice(len(item_ids), size=numItems, replace=False)\n",
    "    sampled_simMatrix = simMatrix[np.ix_(sampled_indices, sampled_indices)]\n",
    "    sampled_item_ids = [item_ids[i] for i in sampled_indices]\n",
    "    sampled_item_costs = [item_costs[i] for i in sampled_indices]\n",
    "\n",
    "    return sampled_simMatrix, sampled_item_ids, sampled_item_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52d5f9",
   "metadata": {},
   "source": [
    "### Yelp - Average plotting across different random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutions(simMatrix, item_ids, item_costs, sample_size, numSamples, maxBudget, dataset_name=None):\n",
    "    '''\n",
    "    Run algorithms over multiple random samples of the dataset, aggregate results, and plot mean +/- std.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.      \n",
    "        item_costs (list): List of item costs of length N.\n",
    "        sample_size (int): Number of items to sample from the dataset.\n",
    "        numSamples (int): Number of random samples to run.\n",
    "        maxBudget (float): Maximum budget for the knapsack problem.\n",
    "        dataset_name (str | None): Optional dataset name for output file naming.\n",
    "    '''\n",
    "    # Cost grid (same for all samples)\n",
    "    num_steps, min_cost = 15, 1\n",
    "    cost_arr = np.linspace(min_cost, maxBudget, num_steps)\n",
    "\n",
    "    algo_names = [\"FC-Greedy\", \"ParetoGreedy\", \"C-Greedy\", \"TopK\"]\n",
    "\n",
    "    # containers across samples\n",
    "    all_objectives = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "    pareto_costs_all = []\n",
    "    pareto_points_counts = []\n",
    "\n",
    "    # frontier size counts per sample\n",
    "    pareto_size_counts = []\n",
    "    fcgreedy_size_counts = []\n",
    "    cgreedy_size_counts = []\n",
    "    topk_size_counts = []\n",
    "\n",
    "    print(f\"Starting processing {numSamples} samples with sample size {sample_size} and max budget {maxBudget}\")\n",
    "\n",
    "    # iterate samples\n",
    "    for sample_index in range(numSamples):\n",
    "        print(f\"Processing sample {sample_index + 1}/{numSamples}\")\n",
    "        \n",
    "        # per-sample containers (will be appended to across budgets)\n",
    "        sample_objectives = {alg: [] for alg in algo_names}\n",
    "        sample_costs = {alg: [] for alg in algo_names}\n",
    "        sample_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # sample the dataset\n",
    "        sampled_simMatrix, sampled_item_ids, sampled_item_costs = sample_dataset(simMatrix, item_ids, item_costs, sample_size)\n",
    "\n",
    "        for budgetVal in cost_arr:\n",
    "            # Initialize Pareto restaurants object\n",
    "            paretoRest = paretoKnapsackRestaurants(n_items=sampled_item_ids,\n",
    "                                                   costs=sampled_item_costs,\n",
    "                                                   simMatrix=sampled_simMatrix,\n",
    "                                                   budget=budgetVal)\n",
    "\n",
    "            # C-Greedy (plain Greedy)\n",
    "            # if \"C-Greedy\" in algo_names:\n",
    "            #     plain_items, curr_objective, curr_cost, runTime = paretoRest.plainGreedy()\n",
    "            #     sample_objectives['C-Greedy'].append(curr_objective)\n",
    "            #     sample_costs['C-Greedy'].append(curr_cost)\n",
    "            #     sample_runtimes['C-Greedy'].append(runTime)\n",
    "            # else:\n",
    "            #     plain_items = []\n",
    "\n",
    "            # C-Greedy (one-guess Greedy Plus)\n",
    "            if \"C-Greedy\" in algo_names:\n",
    "                _, curr_objective, curr_cost, runTime = paretoRest.oneGuessGreedyPlus()\n",
    "                sample_objectives['C-Greedy'].append(curr_objective)\n",
    "                sample_costs['C-Greedy'].append(curr_cost)\n",
    "                sample_runtimes['C-Greedy'].append(runTime)\n",
    "\n",
    "            # Top-k (add items by score until budget is exhausted)\n",
    "            if \"TopK\" in algo_names:\n",
    "                _, curr_objective, curr_cost, runTime = paretoRest.top_k()\n",
    "                sample_objectives['TopK'].append(curr_objective)\n",
    "                sample_costs['TopK'].append(curr_cost)\n",
    "                sample_runtimes['TopK'].append(runTime)\n",
    "\n",
    "        if \"C-Greedy\" in algo_names:\n",
    "            cgreedy_size_counts.append(len(sample_objectives['C-Greedy']))\n",
    "        if \"TopK\" in algo_names:\n",
    "            topk_size_counts.append(len(sample_objectives['TopK']))\n",
    "\n",
    "        # Pareto Greedy + FC-Greedy (computed once per sample at full budget)\n",
    "        if any(alg in algo_names for alg in [\"ParetoGreedy\", \"FC-Greedy\"]):\n",
    "            print(f\"  Running Pareto/grid algorithms for sample {sample_index + 1}\")\n",
    "            paretoRest_full = paretoKnapsackRestaurants(n_items=sampled_item_ids,\n",
    "                                                        costs=sampled_item_costs,\n",
    "                                                        simMatrix=sampled_simMatrix,\n",
    "                                                        budget=maxBudget)\n",
    "        else:\n",
    "            paretoRest_full = None\n",
    "\n",
    "        if \"ParetoGreedy\" in algo_names:\n",
    "            pg1_costs, pg1_objectives, _, pg1_time = paretoRest_full.prefixParetoGreedy_1Guess()\n",
    "        else:\n",
    "            pg1_costs, pg1_objectives, pg1_time = [], [], 0.0\n",
    "\n",
    "        if \"FC-Greedy\" in algo_names:\n",
    "            fc_costs, fc_objectives, fc_time = paretoRest_full.FC_Greedy()\n",
    "        else:\n",
    "            fc_costs, fc_objectives, fc_time = [], [], 0\n",
    "\n",
    "        # Ensure objectives align with the cost_arr length if possible.\n",
    "        # We'll resample/pad to cost_arr length: simplest is to interpolate by cost.\n",
    "        def align_to_cost_arr(costs, objs):\n",
    "            if len(costs) == 0:\n",
    "                return np.zeros_like(cost_arr, dtype=float)\n",
    "            costs = np.array(costs, dtype=float)\n",
    "            objs = np.array(objs, dtype=float)\n",
    "            order = np.argsort(costs)\n",
    "            costs = costs[order]\n",
    "            objs = objs[order]\n",
    "            return np.interp(cost_arr, costs, objs, left=objs[0], right=objs[-1])\n",
    "\n",
    "        if \"ParetoGreedy\" in algo_names:\n",
    "            sample_objectives['ParetoGreedy'] = list(align_to_cost_arr(pg1_costs, pg1_objectives))\n",
    "            sample_runtimes['ParetoGreedy'].append(pg1_time)\n",
    "            pareto_costs_all.extend(pg1_costs)\n",
    "            pareto_points_counts.append(len(pg1_costs))\n",
    "            pareto_size_counts.append(len(pg1_objectives))\n",
    "\n",
    "        if \"FC-Greedy\" in algo_names:\n",
    "            sample_objectives['FC-Greedy'] = list(align_to_cost_arr(fc_costs, fc_objectives))\n",
    "            sample_runtimes['FC-Greedy'].append(fc_time)\n",
    "            fcgreedy_size_counts.append(len(fc_objectives))\n",
    "\n",
    "        # convert per-sample lists to numpy arrays and store in all_objectives\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(sample_objectives[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(cost_arr, dtype=float)\n",
    "            all_objectives[alg].append(arr)\n",
    "            # store total runtime per sample (sum over budgets or single value for pareto)\n",
    "            runtimes = sample_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "        print(f\"Completed sample {sample_index + 1}\")\n",
    "\n",
    "    print(\"All samples processed, computing statistics and plotting\")\n",
    "\n",
    "    # compute mean and std across samples for each algorithm\n",
    "    mean_objectives = {}\n",
    "    std_objectives = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_objectives[alg])  # shape (numSamples, len(cost_arr))\n",
    "        mean_objectives[alg] = np.mean(stacked, axis=0)\n",
    "        std_objectives[alg] = np.std(stacked, axis=0)  # reduce std for better visualization\n",
    "\n",
    "    mean_pareto_points = float(np.mean(pareto_points_counts)) if len(pareto_points_counts) > 0 else 0.0\n",
    "\n",
    "    mean_pareto_size = float(np.mean(pareto_size_counts)) if len(pareto_size_counts) > 0 else 0.0\n",
    "    mean_fcgreedy_size = float(np.mean(fcgreedy_size_counts)) if len(fcgreedy_size_counts) > 0 else 0.0\n",
    "    mean_cgreedy_size = float(np.mean(cgreedy_size_counts)) if len(cgreedy_size_counts) > 0 else 0.0\n",
    "    mean_topk_size = float(np.mean(topk_size_counts)) if len(topk_size_counts) > 0 else 0.0\n",
    "\n",
    "    def sample_scatter_costs(mean_points, rng):\n",
    "        if cost_arr.size == 0 or mean_points <= 0:\n",
    "            return np.array([], dtype=float)\n",
    "        target_count = int(np.clip(np.round(mean_points), 1, cost_arr.size))\n",
    "        base_idx = np.linspace(0, cost_arr.size - 1, target_count)\n",
    "        base_idx = np.round(base_idx).astype(int)\n",
    "        jitter = rng.integers(-1, 2, size=target_count)\n",
    "        idx = np.clip(base_idx + jitter, 0, cost_arr.size - 1)\n",
    "        idx = np.unique(idx)\n",
    "        if idx.size < target_count:\n",
    "            remaining = np.setdiff1d(np.arange(cost_arr.size), idx)\n",
    "            if remaining.size > 0:\n",
    "                extra = rng.choice(remaining, size=min(target_count - idx.size, remaining.size), replace=False)\n",
    "                idx = np.sort(np.concatenate([idx, extra]))\n",
    "        return cost_arr[idx]\n",
    "\n",
    "    # Plot mean objective with shaded std band (consistent with teams plotting)\n",
    "    tab10_colors = plt.get_cmap(\"tab10\").colors\n",
    "    color_map = {\n",
    "        \"TopK\": tab10_colors[4],\n",
    "        \"C-Greedy\": tab10_colors[1],\n",
    "        \"ParetoGreedy\": tab10_colors[3],\n",
    "        \"FC-Greedy\": tab10_colors[0],\n",
    "    }\n",
    "    marker_map = {\n",
    "        \"TopK\": \"o\",\n",
    "        \"C-Greedy\": \"^\",\n",
    "        \"ParetoGreedy\": \"X\",\n",
    "        \"FC-Greedy\": \"P\",\n",
    "    }\n",
    "    linestyle_map = {\n",
    "        \"TopK\": (0, (1, 1)),\n",
    "        \"C-Greedy\": (0, (2, 2)),\n",
    "        \"ParetoGreedy\": (0, (4, 2)),\n",
    "        \"FC-Greedy\": (0, (2, 1, 1, 1)),\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    rng = np.random.default_rng()\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_objectives[alg]\n",
    "        std = std_objectives[alg]\n",
    "        is_pareto = alg in {\"ParetoGreedy\"}\n",
    "        marker_size = 7\n",
    "        if is_pareto:\n",
    "            marker_size = marker_size * 1.1\n",
    "        line_style = linestyle_map.get(alg, (0, (1, 1)))\n",
    "\n",
    "        color = color_map.get(alg, tab10_colors[i % len(tab10_colors)])\n",
    "        marker = marker_map.get(alg, 'o')\n",
    "        zorder = 3\n",
    "        if alg == \"ParetoGreedy\":\n",
    "            zorder = 4\n",
    "\n",
    "        if is_pareto:\n",
    "            ax.plot(cost_arr, mean,\n",
    "                    label=\"_nolegend_\",\n",
    "                    color=color,\n",
    "                    linestyle=line_style,\n",
    "                    linewidth=1.8,\n",
    "                    zorder=zorder)\n",
    "            scatter_costs = sample_scatter_costs(mean_pareto_points, rng)\n",
    "            if scatter_costs.size > 0:\n",
    "                scatter_mean_vals = np.interp(scatter_costs, cost_arr, mean)\n",
    "                ax.scatter(scatter_costs, scatter_mean_vals,\n",
    "                           label=\"_nolegend_\",\n",
    "                           color=color,\n",
    "                           marker=marker,\n",
    "                           s=(marker_size*1.1)**2,\n",
    "                           linewidths=0,\n",
    "                           zorder=zorder + 1)\n",
    "        else:\n",
    "            ax.plot(cost_arr, mean,\n",
    "                    color=color,\n",
    "                    linestyle=line_style,\n",
    "                    marker=marker,\n",
    "                    markersize=marker_size,\n",
    "                    markeredgewidth=0,\n",
    "                    markeredgecolor='none',\n",
    "                    linewidth=1.8,\n",
    "                    zorder=zorder)\n",
    "        ax.fill_between(cost_arr,\n",
    "                        np.clip(mean - std, 0, None),\n",
    "                        mean + std,\n",
    "                        color=color,\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel(r'Cost, $c_\\ell$', fontsize=28)\n",
    "    ax.set_ylabel(r'Objective, $f$', fontsize=28)\n",
    "    ax.set_title(\"\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    # Save figure\n",
    "    from pathlib import Path\n",
    "    base_dir = Path.cwd().resolve().parents[1]\n",
    "    plots_dir = base_dir / \"plots\" / \"knapsack\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    safe_name = (dataset_name or \"dataset\").replace(\" \", \"_\")\n",
    "    out_path = plots_dir / f\"{safe_name}_knapsack.pdf\"\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Runtime summary (latex row)\n",
    "    dataset_label = dataset_name or \"dataset\"\n",
    "    dataset_macro_map = {\n",
    "        \"Yelp-PHX\": r\"\\yelpphoenix\",\n",
    "        \"Yelp-LV\": r\"\\yelpvegas\",\n",
    "    }\n",
    "    dataset_macro = dataset_macro_map.get(dataset_label, rf\"\\\\dataset{{{dataset_label}}}\")\n",
    "    mean_cgreedy_rt = float(np.mean(all_runtimes['C-Greedy'])) if len(all_runtimes['C-Greedy']) > 0 else 0.0\n",
    "    mean_fcgreedy_rt = float(np.mean(all_runtimes['FC-Greedy'])) if len(all_runtimes['FC-Greedy']) > 0 else 0.0\n",
    "    mean_pareto_rt = float(np.mean(all_runtimes['ParetoGreedy'])) if len(all_runtimes['ParetoGreedy']) > 0 else 0.0\n",
    "    mean_topk_rt = float(np.mean(all_runtimes['TopK'])) if len(all_runtimes['TopK']) > 0 else 0.0\n",
    "    runtime_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_rt:.3f} \"\n",
    "        f\"& -- \"\n",
    "        f\"& {mean_fcgreedy_rt:.3f} \"\n",
    "        f\"& {mean_pareto_rt:.3f} \"\n",
    "        f\"& {mean_topk_rt:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(runtime_row)\n",
    "\n",
    "    # Mean frontier sizes summary (latex row)\n",
    "    frontier_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_size:.3f} \"\n",
    "        f\"& -- \"\n",
    "        f\"& {mean_fcgreedy_size:.3f} \"\n",
    "        f\"& {mean_pareto_size:.3f} \"\n",
    "        f\"& {mean_topk_size:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(frontier_row)\n",
    "\n",
    "    summary_dir = plots_dir / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    runtimes_path = summary_dir / \"runtimes.txt\"\n",
    "    frontier_path = summary_dir / \"frontier-size.txt\"\n",
    "    with open(runtimes_path, \"a\", encoding=\"utf-8\") as runtime_file:\n",
    "        runtime_file.write(runtime_row + \"\\n\")\n",
    "    with open(frontier_path, \"a\", encoding=\"utf-8\") as frontier_file:\n",
    "        frontier_file.write(frontier_row + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa65a09",
   "metadata": {},
   "source": [
    "### Yelp Phoenix Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Yelp dataset\n",
    "data_path = '../../datasets/pickled_data/yelp/yelp_phoenix_'\n",
    "    \n",
    "#Import pickled data\n",
    "with open(data_path + 'ids.pkl', \"rb\") as fp:\n",
    "    phoenix_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'sim.pkl', \"rb\") as fp:\n",
    "    phoenix_simMatrix = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'costs.pkl', \"rb\") as fp:\n",
    "    phoenix_costs = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call findApproximateParetoSolutions (adjust parameters as needed)\n",
    "sample_size = 200\n",
    "numSamples = 2  # e.g., number of random samples\n",
    "maxBudget = 140\n",
    "\n",
    "findApproximateParetoSolutions(phoenix_simMatrix, phoenix_ids, phoenix_costs, sample_size, numSamples, maxBudget, dataset_name=\"Yelp-PHX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4abbb1",
   "metadata": {},
   "source": [
    "### Yelp Vegas Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c47324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Vegas dataset\n",
    "data_path = '../../datasets/pickled_data/yelp/yelp_vegas_' \n",
    "\n",
    "#Import pickled data\n",
    "with open(data_path + 'ids.pkl', \"rb\") as fp:\n",
    "    vegas_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'sim.pkl', \"rb\") as fp:\n",
    "    vegas_simMatrix = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'costs.pkl', \"rb\") as fp:\n",
    "    vegas_costs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call findApproximateParetoSolutions (adjust parameters as needed)\n",
    "sample_size = 300\n",
    "numSamples = 2  # e.g., number of random samples\n",
    "maxBudget = 100\n",
    "\n",
    "findApproximateParetoSolutions(vegas_simMatrix, vegas_ids, vegas_costs, sample_size, numSamples, maxBudget, dataset_name=\"Yelp-LV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f3ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
