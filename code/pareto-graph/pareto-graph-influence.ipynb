{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoGraphInfluence import *\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Enable LaTeX rendering if available (fallback to Matplotlib text otherwise)\n",
    "if shutil.which(\"latex\"):\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\"text.usetex\": False})\n",
    "\n",
    "# Import influence datasets\n",
    "data_path_HEPT = '../../datasets/raw_data/influence/NetHEPT/hep.txt'\n",
    "data_path_PHY = '../../datasets/raw_data/influence/NetPHY/phy.txt'\n",
    "\n",
    "G_HEPT = import_influence_data(data_path_HEPT)\n",
    "G_PHY = import_influence_data(data_path_PHY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutionsInfluenceGraph(G, num_samples=10, num_runs=5, sample_size=200, maxDiameter=None, dataset_name=\"\"):\n",
    "    '''\n",
    "    Run graph-diameter algorithms over multiple runs and plot mean +/- std (Influence vs Diameter).\n",
    "    Parameters:\n",
    "    - G: Graph\n",
    "    - num_samples: Number of Monte Carlo samples per run\n",
    "    - num_runs: Number of independent runs\n",
    "    - sample_size: Optional node subsample size\n",
    "    - maxDiameter: Optional diameter max for plotting grid\n",
    "    - dataset_name: Name of the dataset for plotting\n",
    "    '''\n",
    "    algo_names = [\"ParetoGreedy-Diameter\", \"PruneGraph\", \"PlainGreedy\", \"TopK-degree\"]\n",
    "\n",
    "    all_influences = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "    cgreedy_size_counts = []\n",
    "    prune_size_counts = []\n",
    "    distance_size_counts = []\n",
    "    topk_size_counts = []\n",
    "\n",
    "    for run_idx in range(num_runs):\n",
    "        subG, sub_nodes = sample_graph(G, sample_size=sample_size, seed=run_idx)\n",
    "        pairwise_costs, sub_nodes = compute_pairwise_costs_from_graph(subG, sub_nodes)\n",
    "\n",
    "        if maxDiameter is None:\n",
    "            maxDiameter_run = 1.5 * float(np.max(pairwise_costs)) if pairwise_costs.size > 0 else 1.0\n",
    "        else:\n",
    "            maxDiameter_run = maxDiameter\n",
    "\n",
    "        num_steps, min_diameter = 8, 0.0\n",
    "        diameter_arr = np.linspace(min_diameter, maxDiameter_run, num_steps)\n",
    "\n",
    "        def align_to_diameter_arr(diameters, infls):\n",
    "            if len(diameters) == 0 or len(infls) == 0:\n",
    "                return np.full_like(diameter_arr, np.nan, dtype=float)\n",
    "            diameters = np.array(diameters, dtype=float)\n",
    "            infls = np.array(infls, dtype=float)\n",
    "            min_len = min(len(diameters), len(infls))\n",
    "            diameters = diameters[:min_len]\n",
    "            infls = infls[:min_len]\n",
    "            agg = {}\n",
    "            for d, c in zip(diameters, infls):\n",
    "                if d in agg:\n",
    "                    agg[d] = max(agg[d], c)\n",
    "                else:\n",
    "                    agg[d] = c\n",
    "            if len(agg) == 0:\n",
    "                return np.full_like(diameter_arr, np.nan, dtype=float)\n",
    "            diameters_sorted = np.array(sorted(agg.keys()), dtype=float)\n",
    "            infls_sorted = np.array([agg[d] for d in diameters_sorted], dtype=float)\n",
    "            return np.interp(diameter_arr, diameters_sorted, infls_sorted, left=infls_sorted[0], right=infls_sorted[-1])\n",
    "\n",
    "        graph_samples = None\n",
    "        if num_samples is not None and num_samples > 0:\n",
    "            pareto_tmp = paretoGraphInfluence(G=subG, pairwise_costs=pairwise_costs, nodes=sub_nodes, num_samples=num_samples)\n",
    "            graph_samples = pareto_tmp.graph_samples\n",
    "\n",
    "        run_influences = {alg: [] for alg in algo_names}\n",
    "        run_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        pareto = paretoGraphInfluence(G=subG, pairwise_costs=pairwise_costs, nodes=sub_nodes, num_samples=num_samples, graph_samples=graph_samples)\n",
    "        diameters, best_infl, _, _, runTime = pareto.ParetoGreedyDiameter()\n",
    "        run_influences['ParetoGreedy-Diameter'] = list(align_to_diameter_arr(diameters, best_infl))\n",
    "        run_runtimes['ParetoGreedy-Diameter'].append(runTime)\n",
    "        cgreedy_size_counts.append(len(diameters))\n",
    "\n",
    "        pg_diam, pg_infl, _, _, pg_time = pareto.plainGreedyDistanceScaled()\n",
    "        run_influences['PlainGreedy'] = list(align_to_diameter_arr(pg_diam, pg_infl))\n",
    "        run_runtimes['PlainGreedy'].append(pg_time)\n",
    "        distance_size_counts.append(len(pg_diam))\n",
    "\n",
    "        tk_diam, tk_infl, _, _, tk_time = pareto.topKDistanceScaled()\n",
    "        run_influences['TopK-degree'] = list(align_to_diameter_arr(tk_diam, tk_infl))\n",
    "        run_runtimes['TopK-degree'].append(tk_time)\n",
    "        topk_size_counts.append(len(tk_diam))\n",
    "\n",
    "        pr_radii, pr_infl, _, _, pr_time = pareto.graphPruning()\n",
    "        run_influences['PruneGraph'] = list(align_to_diameter_arr(pr_radii, pr_infl))\n",
    "        run_runtimes['PruneGraph'].append(pr_time)\n",
    "        prune_size_counts.append(len(pr_radii))\n",
    "\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(run_influences[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.full_like(diameter_arr, np.nan, dtype=float)\n",
    "            all_influences[alg].append(arr)\n",
    "            runtimes = run_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "    mean_influences = {}\n",
    "    std_influences = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_influences[alg])\n",
    "        mean_influences[alg] = np.nanmean(stacked, axis=0)\n",
    "        std_influences[alg] = np.nanstd(stacked, axis=0)\n",
    "\n",
    "    mean_cgreedy_size = float(np.mean(cgreedy_size_counts)) if len(cgreedy_size_counts) > 0 else 0.0\n",
    "    mean_prune_size = float(np.mean(prune_size_counts)) if len(prune_size_counts) > 0 else 0.0\n",
    "    mean_distance_size = float(np.mean(distance_size_counts)) if len(distance_size_counts) > 0 else 0.0\n",
    "    mean_topk_size = float(np.mean(topk_size_counts)) if len(topk_size_counts) > 0 else 0.0\n",
    "\n",
    "    mean_frontier_sizes = {\n",
    "        \"ParetoGreedy-Diameter\": mean_cgreedy_size,\n",
    "        \"PruneGraph\": mean_prune_size,\n",
    "        \"PlainGreedy\": mean_distance_size,\n",
    "        \"TopK-degree\": mean_topk_size,\n",
    "    }\n",
    "\n",
    "    tab10_colors = plt.get_cmap(\"tab10\").colors\n",
    "    color_map = {\n",
    "        \"ParetoGreedy-Diameter\": tab10_colors[2],\n",
    "        \"PruneGraph\": tab10_colors[3],\n",
    "        \"PlainGreedy\": tab10_colors[1],\n",
    "        \"TopK-degree\": tab10_colors[0],\n",
    "    }\n",
    "    marker_map = {\n",
    "        \"ParetoGreedy-Diameter\": \"X\",\n",
    "        \"PruneGraph\": \"o\",\n",
    "        \"PlainGreedy\": \"s\",\n",
    "        \"TopK-degree\": \"^\",\n",
    "    }\n",
    "    linestyle_map = {\n",
    "        \"ParetoGreedy-Diameter\": (0, (3, 2)),\n",
    "        \"PruneGraph\": (0, (4, 2)),\n",
    "        \"PlainGreedy\": (0, (2, 2)),\n",
    "        \"TopK-degree\": (0, (1, 1)),\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    def pick_marker_indices(count):\n",
    "        if diameter_arr.size == 0 or count <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "        count = int(max(2, min(diameter_arr.size, count)))\n",
    "        if count == 1:\n",
    "            return np.array([0], dtype=int)\n",
    "        step = (diameter_arr.size - 1) / float(count - 1)\n",
    "        max_offset = max(0.0, step - 1.0)\n",
    "        offset = rng.uniform(0.0, max_offset) if max_offset > 0 else 0.0\n",
    "        idx = np.round(offset + step * np.arange(count)).astype(int)\n",
    "        idx = np.clip(idx, 0, diameter_arr.size - 1)\n",
    "        idx = np.unique(idx)\n",
    "        if idx.size < 2:\n",
    "            idx = np.unique(np.round(np.linspace(0, diameter_arr.size - 1, count)).astype(int))\n",
    "        return idx\n",
    "\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_influences[alg]\n",
    "        std = std_influences[alg] * 0.5\n",
    "        is_pareto = alg == \"ParetoGreedy-Diameter\"\n",
    "        marker_size = 7 if is_pareto else 6\n",
    "        line_style = linestyle_map.get(alg, (0, (1, 1)))\n",
    "\n",
    "        color = color_map.get(alg, tab10_colors[i % len(tab10_colors)])\n",
    "        marker = marker_map.get(alg, \"o\")\n",
    "        zorder = 4 if is_pareto else 3\n",
    "\n",
    "        ax.plot(diameter_arr, mean,\n",
    "                color=color,\n",
    "                linestyle=line_style,\n",
    "                linewidth=1.8,\n",
    "                zorder=zorder)\n",
    "        marker_count = int(np.round(mean_frontier_sizes.get(alg, 0.0)))\n",
    "        marker_idx = pick_marker_indices(marker_count)\n",
    "        if marker_idx.size > 0:\n",
    "            ax.scatter(diameter_arr[marker_idx], mean[marker_idx],\n",
    "                       color=color,\n",
    "                       marker=marker,\n",
    "                       s=marker_size**2,\n",
    "                       edgecolor='k',\n",
    "                       linewidths=0.6,\n",
    "                       zorder=zorder + 1)\n",
    "        ax.fill_between(diameter_arr,\n",
    "                        np.clip(mean - std, 0, None),\n",
    "                        np.clip(mean + std, 0, None),\n",
    "                        color=color,\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel(r'Seed diameter, $c_d$', fontsize=28)\n",
    "    ax.set_ylabel(r'Expected influence, $f$', fontsize=28)\n",
    "    ax.set_title(\"\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    from pathlib import Path\n",
    "    base_dir = Path.cwd().resolve().parents[1]\n",
    "    plots_dir = base_dir / \"plots\" / \"graph\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    safe_name = (dataset_name or \"dataset\").replace(\" \", \"_\")\n",
    "    out_path = plots_dir / f\"{safe_name}_graph.pdf\"\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    dataset_label = dataset_name or \"dataset\"\n",
    "    dataset_macro = rf\"\\\\dataset{{{dataset_label}}}\"\n",
    "    mean_cgreedy_rt = float(np.mean(all_runtimes['ParetoGreedy-Diameter'])) if len(all_runtimes['ParetoGreedy-Diameter']) > 0 else 0.0\n",
    "    mean_prune_rt = float(np.mean(all_runtimes['PruneGraph'])) if len(all_runtimes['PruneGraph']) > 0 else 0.0\n",
    "    mean_distance_rt = float(np.mean(all_runtimes['PlainGreedy'])) if len(all_runtimes['PlainGreedy']) > 0 else 0.0\n",
    "    mean_topk_rt = float(np.mean(all_runtimes['TopK-degree'])) if len(all_runtimes['TopK-degree']) > 0 else 0.0\n",
    "    runtime_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_rt:.3f} \"\n",
    "        f\"& {mean_prune_rt:.3f} \"\n",
    "        f\"& {mean_distance_rt:.3f} \"\n",
    "        f\"& {mean_topk_rt:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(runtime_row)\n",
    "\n",
    "    frontier_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_size:.3f} \"\n",
    "        f\"& {mean_prune_size:.3f} \"\n",
    "        f\"& {mean_distance_size:.3f} \"\n",
    "        f\"& {mean_topk_size:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(frontier_row)\n",
    "\n",
    "    summary_dir = plots_dir / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    runtimes_path = summary_dir / \"runtimes.txt\"\n",
    "    frontier_path = summary_dir / \"frontier-size.txt\"\n",
    "    with open(runtimes_path, \"a\", encoding=\"utf-8\") as runtime_file:\n",
    "        runtime_file.write(runtime_row + \"\\n\")\n",
    "    with open(frontier_path, \"a\", encoding=\"utf-8\") as frontier_file:\n",
    "        frontier_file.write(frontier_row + \"\\n\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb440ff",
   "metadata": {},
   "source": [
    "### NetPHY Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5421e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_samples = 5\n",
    "num_runs = 2\n",
    "sample_size = 2\n",
    "\n",
    "# Run for NetPHY\n",
    "findApproximateParetoSolutionsInfluenceGraph(G_PHY, num_samples=num_samples, num_runs=num_runs, \n",
    "                                             sample_size=sample_size, dataset_name=\"NetPHY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643fa02",
   "metadata": {},
   "source": [
    "### NetHEPT Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_samples = 5\n",
    "num_runs = 2\n",
    "sample_size = 1673\n",
    "findApproximateParetoSolutionsInfluenceGraph(G_HEPT, num_samples=num_samples, num_runs=num_runs, sample_size=sample_size, dataset_name=\"NetHEPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5912d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
