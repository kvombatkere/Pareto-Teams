{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be559159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoGraphRestaurants import *\n",
    "\n",
    "import pickle\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Enable LaTeX rendering if available (fallback to Matplotlib text otherwise)\n",
    "if shutil.which(\"latex\"):\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\"text.usetex\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac2de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sample numItems from the dataset\n",
    "def sample_dataset(simMatrix, graphMat, item_ids, numItems):\n",
    "    '''\n",
    "    Samples a subset of items from the dataset.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        graphMat (np.ndarray): Graph distance matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.\n",
    "        numItems (int): Number of items to sample.\n",
    "    Returns:\n",
    "        sampled_simMatrix (np.ndarray): Sampled similarity matrix of shape (numItems, numItems).\n",
    "        sampled_graphMat (np.ndarray): Sampled graph distance matrix of shape (numItems, numItems).\n",
    "        sampled_item_ids (list): List of sampled item IDs of length numItems.\n",
    "    '''\n",
    "    if numItems is None or numItems <= 0 or numItems >= len(item_ids):\n",
    "        return simMatrix, graphMat, item_ids\n",
    "    sampled_indices = np.random.choice(len(item_ids), size=numItems, replace=False)\n",
    "    sampled_simMatrix = simMatrix[np.ix_(sampled_indices, sampled_indices)]\n",
    "    sampled_graphMat = graphMat[np.ix_(sampled_indices, sampled_indices)]\n",
    "    sampled_item_ids = [item_ids[i] for i in sampled_indices]\n",
    "    return sampled_simMatrix, sampled_graphMat, sampled_item_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5bd454",
   "metadata": {},
   "source": [
    "### Yelp - Average plotting across different random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutionsRestaurantsGraph(simMatrix, graphMat, item_ids, sample_size, num_samples=10, maxDiameter=None, dataset_name=\"\"):\n",
    "    '''\n",
    "    Run graph-diameter algorithms over multiple random samples, aggregate results, and plot mean +/- std.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        graphMat (np.ndarray): Graph distance matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.\n",
    "        sample_size (int): Number of items to sample from the dataset.\n",
    "        num_samples (int): Number of random samples to run.\n",
    "        maxDiameter (float | None): Maximum diameter for plotting grid. If None, inferred from graphMat.\n",
    "        dataset_name (str | None): Optional dataset name for output file naming.\n",
    "    '''\n",
    "    if maxDiameter is None:\n",
    "        maxDiameter = float(np.max(graphMat)) if np.asarray(graphMat).size > 0 else 1.0\n",
    "\n",
    "    # Diameter grid (same for all samples)\n",
    "    num_steps, min_diameter = 15, 0.0\n",
    "    diameter_arr = np.linspace(min_diameter, maxDiameter, num_steps)\n",
    "\n",
    "    algo_names = [\"C-Greedy-Diameter\", \"PruneGraph\", \"DistanceGreedy\", \"TopK-degree\"]\n",
    "\n",
    "    def align_to_diameter_arr(diameters, objs):\n",
    "        if len(diameters) == 0 or len(objs) == 0:\n",
    "            return np.zeros_like(diameter_arr, dtype=float)\n",
    "        diameters = np.array(diameters, dtype=float)\n",
    "        objs = np.array(objs, dtype=float)\n",
    "        min_len = min(len(diameters), len(objs))\n",
    "        diameters = diameters[:min_len]\n",
    "        objs = objs[:min_len]\n",
    "        agg = {}\n",
    "        for d, o in zip(diameters, objs):\n",
    "            if d in agg:\n",
    "                agg[d] = max(agg[d], o)\n",
    "            else:\n",
    "                agg[d] = o\n",
    "        if len(agg) == 0:\n",
    "            return np.zeros_like(diameter_arr, dtype=float)\n",
    "        diameters_sorted = np.array(sorted(agg.keys()), dtype=float)\n",
    "        objs_sorted = np.array([agg[d] for d in diameters_sorted], dtype=float)\n",
    "        return np.interp(diameter_arr, diameters_sorted, objs_sorted, left=objs_sorted[0], right=objs_sorted[-1])\n",
    "\n",
    "    all_objectives = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "    cgreedy_size_counts = []\n",
    "    prune_size_counts = []\n",
    "    distance_size_counts = []\n",
    "    topk_size_counts = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        sampled_sim, sampled_graph, sampled_ids = sample_dataset(simMatrix, graphMat, item_ids, sample_size)\n",
    "        dist_mat = sampled_graph\n",
    "\n",
    "        sample_objectives = {alg: [] for alg in algo_names}\n",
    "        sample_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        pareto = paretoGraphRestaurants(n_items=sampled_ids, simMatrix=sampled_sim, pairwise_costs=dist_mat)\n",
    "\n",
    "        diameters, best_objs, _, _, runTime = pareto.ParetoGreedyDiameter()\n",
    "        sample_objectives['C-Greedy-Diameter'] = list(align_to_diameter_arr(diameters, best_objs))\n",
    "        sample_runtimes['C-Greedy-Diameter'].append(runTime)\n",
    "        cgreedy_size_counts.append(len(diameters))\n",
    "\n",
    "        pg_diam, pg_objs, _, _, pg_time = pareto.plainGreedyDistanceScaled()\n",
    "        sample_objectives['DistanceGreedy'] = list(align_to_diameter_arr(pg_diam, pg_objs))\n",
    "        sample_runtimes['DistanceGreedy'].append(pg_time)\n",
    "        distance_size_counts.append(len(pg_diam))\n",
    "\n",
    "        tk_diam, tk_objs, _, _, tk_time = pareto.topKDegree()\n",
    "        sample_objectives['TopK-degree'] = list(align_to_diameter_arr(tk_diam, tk_objs))\n",
    "        sample_runtimes['TopK-degree'].append(tk_time)\n",
    "        topk_size_counts.append(len(tk_diam))\n",
    "\n",
    "        pr_radii, pr_objs, _, _, pr_time = pareto.graphPruning()\n",
    "        sample_objectives['PruneGraph'] = list(align_to_diameter_arr(pr_radii, pr_objs))\n",
    "        sample_runtimes['PruneGraph'].append(pr_time)\n",
    "        prune_size_counts.append(len(pr_radii))\n",
    "\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(sample_objectives[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(diameter_arr, dtype=float)\n",
    "            all_objectives[alg].append(arr)\n",
    "            runtimes = sample_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "    mean_objectives = {}\n",
    "    std_objectives = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_objectives[alg])\n",
    "        mean_objectives[alg] = np.mean(stacked, axis=0)\n",
    "        std_objectives[alg] = np.std(stacked, axis=0)\n",
    "\n",
    "    mean_cgreedy_size = float(np.mean(cgreedy_size_counts)) if len(cgreedy_size_counts) > 0 else 0.0\n",
    "    mean_prune_size = float(np.mean(prune_size_counts)) if len(prune_size_counts) > 0 else 0.0\n",
    "    mean_distance_size = float(np.mean(distance_size_counts)) if len(distance_size_counts) > 0 else 0.0\n",
    "    mean_topk_size = float(np.mean(topk_size_counts)) if len(topk_size_counts) > 0 else 0.0\n",
    "\n",
    "    mean_frontier_sizes = {\n",
    "        \"C-Greedy-Diameter\": mean_cgreedy_size,\n",
    "        \"PruneGraph\": mean_prune_size,\n",
    "        \"DistanceGreedy\": mean_distance_size,\n",
    "        \"TopK-degree\": mean_topk_size,\n",
    "    }\n",
    "\n",
    "    tab10_colors = plt.get_cmap(\"tab10\").colors\n",
    "    color_map = {\n",
    "        \"C-Greedy-Diameter\": tab10_colors[2],\n",
    "        \"PruneGraph\": tab10_colors[3],\n",
    "        \"DistanceGreedy\": tab10_colors[1],\n",
    "        \"TopK-degree\": tab10_colors[0],\n",
    "    }\n",
    "    marker_map = {\n",
    "        \"C-Greedy-Diameter\": \"X\",\n",
    "        \"PruneGraph\": \"o\",\n",
    "        \"DistanceGreedy\": \"s\",\n",
    "        \"TopK-degree\": \"^\",\n",
    "    }\n",
    "    linestyle_map = {\n",
    "        \"C-Greedy-Diameter\": (0, (3, 2)),\n",
    "        \"PruneGraph\": (0, (4, 2)),\n",
    "        \"DistanceGreedy\": (0, (2, 2)),\n",
    "        \"TopK-degree\": (0, (1, 1)),\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    def pick_marker_positions(count):\n",
    "        if count <= 0:\n",
    "            return np.array([], dtype=float)\n",
    "        count = int(max(2, np.round(count)))\n",
    "        if diameter_arr.size == 0:\n",
    "            return np.array([], dtype=float)\n",
    "        d_min = float(diameter_arr.min())\n",
    "        d_max = float(diameter_arr.max())\n",
    "        if count == 1 or d_max <= d_min:\n",
    "            return np.array([d_min], dtype=float)\n",
    "        step = (d_max - d_min) / float(count - 1)\n",
    "        max_offset = 0.5 * step\n",
    "        offset = rng.uniform(0.0, max_offset) if max_offset > 0 else 0.0\n",
    "        positions = d_min + offset + step * np.arange(count)\n",
    "        return np.clip(positions, d_min, d_max)\n",
    "\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_objectives[alg]\n",
    "        std = std_objectives[alg]\n",
    "        is_pareto = alg == \"C-Greedy-Diameter\"\n",
    "        marker_size = 7 if is_pareto else 6\n",
    "        line_style = linestyle_map.get(alg, (0, (1, 1)))\n",
    "\n",
    "        color = color_map.get(alg, tab10_colors[i % len(tab10_colors)])\n",
    "        marker = marker_map.get(alg, 'o')\n",
    "        zorder = 4 if is_pareto else 3\n",
    "\n",
    "        ax.plot(diameter_arr, mean,\n",
    "                color=color,\n",
    "                linestyle=line_style,\n",
    "                linewidth=1.8,\n",
    "                zorder=zorder)\n",
    "        marker_count = mean_frontier_sizes.get(alg, 0.0)\n",
    "        if alg in {\"C-Greedy-Diameter\", \"DistanceGreedy\"}:\n",
    "            marker_count *= 0.02\n",
    "\n",
    "        marker_x = pick_marker_positions(marker_count)\n",
    "        if marker_x.size > 0:\n",
    "            marker_y = np.interp(marker_x, diameter_arr, mean)\n",
    "            ax.scatter(marker_x, marker_y,\n",
    "                       color=color,\n",
    "                       marker=marker,\n",
    "                       s=marker_size**2,\n",
    "                       edgecolor='k',\n",
    "                       linewidths=0.6,\n",
    "                       zorder=zorder + 1)\n",
    "        ax.fill_between(diameter_arr,\n",
    "                        np.clip(mean - std, 0, None),\n",
    "                        np.clip(mean + std, 0, None),\n",
    "                        color=color,\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel(r'Diameter, $c_d$', fontsize=28)\n",
    "    ax.set_ylabel(r'Objective, $f$', fontsize=28)\n",
    "    ax.set_title(\"\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    from pathlib import Path\n",
    "    base_dir = Path.cwd().resolve().parents[1]\n",
    "    plots_dir = base_dir / \"plots\" / \"graph\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    safe_name = (dataset_name or \"dataset\").replace(\" \", \"_\")\n",
    "    out_path = plots_dir / f\"{safe_name}_graph.pdf\"\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    dataset_label = dataset_name or \"dataset\"\n",
    "    dataset_macro = rf\"\\\\dataset{{{dataset_label}}}\"\n",
    "    mean_cgreedy_rt = float(np.mean(all_runtimes['C-Greedy-Diameter'])) if len(all_runtimes['C-Greedy-Diameter']) > 0 else 0.0\n",
    "    mean_prune_rt = float(np.mean(all_runtimes['PruneGraph'])) if len(all_runtimes['PruneGraph']) > 0 else 0.0\n",
    "    mean_distance_rt = float(np.mean(all_runtimes['DistanceGreedy'])) if len(all_runtimes['DistanceGreedy']) > 0 else 0.0\n",
    "    mean_topk_rt = float(np.mean(all_runtimes['TopK-degree'])) if len(all_runtimes['TopK-degree']) > 0 else 0.0\n",
    "    runtime_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_rt:.3f} \"\n",
    "        f\"& {mean_prune_rt:.3f} \"\n",
    "        f\"& {mean_distance_rt:.3f} \"\n",
    "        f\"& {mean_topk_rt:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(runtime_row)\n",
    "\n",
    "    frontier_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_size:.3f} \"\n",
    "        f\"& {mean_prune_size:.3f} \"\n",
    "        f\"& {mean_distance_size:.3f} \"\n",
    "        f\"& {mean_topk_size:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(frontier_row)\n",
    "\n",
    "    summary_dir = plots_dir / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    runtimes_path = summary_dir / \"runtimes.txt\"\n",
    "    frontier_path = summary_dir / \"frontier-size.txt\"\n",
    "    with open(runtimes_path, \"a\", encoding=\"utf-8\") as runtime_file:\n",
    "        runtime_file.write(runtime_row + \"\\n\")\n",
    "    with open(frontier_path, \"a\", encoding=\"utf-8\") as frontier_file:\n",
    "        frontier_file.write(frontier_row + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5a8d3",
   "metadata": {},
   "source": [
    "### Yelp Phoenix Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Yelp Phoenix dataset\n",
    "data_path = '../../datasets/pickled_data/yelp/yelp_phoenix_'\n",
    "phoenix_ids, phoenix_simMatrix = import_yelp_data(data_path)\n",
    "with open(data_path + 'graphMat.pkl', 'rb') as f:\n",
    "    phoenix_graphMat = pickle.load(f)\n",
    "\n",
    "# Adjust parameters as needed\n",
    "sample_size = 800\n",
    "num_samples = 10\n",
    "findApproximateParetoSolutionsRestaurantsGraph(phoenix_simMatrix, phoenix_graphMat, phoenix_ids, sample_size, num_samples, dataset_name=\"Yelp_Phoenix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac45821",
   "metadata": {},
   "source": [
    "### Yelp Vegas Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Yelp Vegas dataset\n",
    "data_path = '../../datasets/pickled_data/yelp/yelp_vegas_'\n",
    "vegas_ids, vegas_simMatrix = import_yelp_data(data_path)\n",
    "with open(data_path + 'graphMat.pkl', 'rb') as f:\n",
    "    vegas_graphMat = pickle.load(f)\n",
    "\n",
    "# Adjust parameters as needed\n",
    "sample_size = 1200\n",
    "num_samples = 10\n",
    "findApproximateParetoSolutionsRestaurantsGraph(vegas_simMatrix, vegas_graphMat, vegas_ids, sample_size, num_samples, dataset_name=\"Yelp_Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fd8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
