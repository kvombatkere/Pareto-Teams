{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoGraphTeams import *\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Enable LaTeX rendering if available (fallback to Matplotlib text otherwise)\n",
    "if shutil.which(\"latex\"):\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\"text.usetex\": False})\n",
    "\n",
    "# Import datasets\n",
    "# IMDB\n",
    "imdb_experts_1, imdb_tasks_1, imdb_costs_1, _ = import_pickled_datasets('imdb', 1)\n",
    "imdb_experts_2, imdb_tasks_2, imdb_costs_2, _ = import_pickled_datasets('imdb', 2)\n",
    "# imdb_experts_3, imdb_tasks_3, imdb_costs_3, _ = import_pickled_datasets('imdb', 3)\n",
    "\n",
    "# Bibsonomy\n",
    "bbsm_experts_1, bbsm_tasks_1, bbsm_costs_1, _ = import_pickled_datasets('bbsm', 1)\n",
    "# bbsm_experts_2, bbsm_tasks_2, bbsm_costs_2, _ = import_pickled_datasets('bbsm', 2)\n",
    "\n",
    "# Freelancer\n",
    "fl_experts_1, fl_tasks_1, fl_costs_1, _ = import_pickled_datasets('freelancer', 1)\n",
    "# fl_experts_2, fl_tasks_2, fl_costs_2, _ = import_pickled_datasets('freelancer', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da421666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expertCoordinationAdjacencyMatrix(expert_list, use_jaccard=False):\n",
    "    '''\n",
    "    Create a coordination graph adjacency matrix of dimension len(expert_list)*len(expert_list) from a list of experts.\n",
    "    If use_jaccard is True, the distance between two experts is the Jaccard distance.\n",
    "    Otherwise, the distance between two experts is defined as 10*e^(-0.1*D) where D is the number of skills they have in common.\n",
    "    '''\n",
    "    n = len(expert_list)\n",
    "    graphmat = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        skills_i = set(expert_list[i])\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                skills_j = set(expert_list[j])\n",
    "                if use_jaccard:\n",
    "                    union = skills_i | skills_j\n",
    "                    if len(union) == 0:\n",
    "                        graphmat[i, j] = 0.0\n",
    "                    else:\n",
    "                        inter = skills_i & skills_j\n",
    "                        graphmat[i, j] = 1.0 - (len(inter) / len(union))\n",
    "                else:\n",
    "                    common_skills = len(skills_i & skills_j)\n",
    "                    graphmat[i, j] = np.exp(-0.1 * common_skills)\n",
    "    \n",
    "    return graphmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a928fa",
   "metadata": {},
   "source": [
    "### Average Plotting across Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6df044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutions(tasks_list, experts_list, graphmat,\n",
    "                                   sizeUniverse, numExperts, numTasks, maxDiameter,\n",
    "                                   dataset_name=None, start_index=0):\n",
    "    '''\n",
    "    Run graph-diameter algorithm over multiple tasks, aggregate results, and plot mean +/- std.\n",
    "    '''\n",
    "    # Diameter grid (same for all tasks)\n",
    "    num_steps, min_diameter = 15, 0.0\n",
    "    diameter_arr = np.linspace(min_diameter, maxDiameter, num_steps)\n",
    "\n",
    "    algo_names = [\"C-Greedy-Diameter\", \"PruneGraph\", \"DistanceGreedy\", \"TopDegree\"]\n",
    "\n",
    "    def align_to_diameter_arr(diameters, covs):\n",
    "        if len(diameters) == 0 or len(covs) == 0:\n",
    "            return np.zeros_like(diameter_arr, dtype=float)\n",
    "        diameters = np.array(diameters, dtype=float)\n",
    "        covs = np.array(covs, dtype=float)\n",
    "\n",
    "        # Ensure matching lengths\n",
    "        min_len = min(len(diameters), len(covs))\n",
    "        diameters = diameters[:min_len]\n",
    "        covs = covs[:min_len]\n",
    "\n",
    "        # Aggregate duplicate diameters by taking max coverage\n",
    "        agg = {}\n",
    "        for d, c in zip(diameters, covs):\n",
    "            if d in agg:\n",
    "                agg[d] = max(agg[d], c)\n",
    "            else:\n",
    "                agg[d] = c\n",
    "        if len(agg) == 0:\n",
    "            return np.zeros_like(diameter_arr, dtype=float)\n",
    "        diameters_sorted = np.array(sorted(agg.keys()), dtype=float)\n",
    "        covs_sorted = np.array([agg[d] for d in diameters_sorted], dtype=float)\n",
    "\n",
    "        return np.interp(diameter_arr, diameters_sorted, covs_sorted, left=covs_sorted[0], right=covs_sorted[-1])\n",
    "\n",
    "    # containers across tasks\n",
    "    all_coverages = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "    # frontier size counts per task\n",
    "    cgreedy_size_counts = []\n",
    "    prune_size_counts = []\n",
    "    distance_size_counts = []\n",
    "    topk_size_counts = []\n",
    "\n",
    "    # iterate tasks\n",
    "    for task_index in range(start_index, start_index + numTasks):\n",
    "        # per-task containers\n",
    "        task_coverages = {alg: [] for alg in algo_names}\n",
    "        task_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # Initialize Pareto teams object\n",
    "        pareto_diam = paretoGraph(task=tasks_list[task_index],\n",
    "                                  n_experts=experts_list[:numExperts],\n",
    "                                  pairwise_costs=graphmat[:numExperts, :numExperts],\n",
    "                                  size_univ=sizeUniverse,\n",
    "                                  budget=1)\n",
    "\n",
    "        diameters, best_coverages, _, _, runTime = pareto_diam.ParetoGreedyDiameter()\n",
    "        diameters = np.array(diameters, dtype=float)\n",
    "        best_coverages = np.array(best_coverages, dtype=float)\n",
    "\n",
    "        # Interpolate to shared diameter grid\n",
    "        task_coverages['C-Greedy-Diameter'] = list(align_to_diameter_arr(diameters, best_coverages))\n",
    "        task_runtimes['C-Greedy-Diameter'].append(runTime)\n",
    "        cgreedy_size_counts.append(len(diameters))\n",
    "\n",
    "        # Plain Greedy (distance-scaled) baseline\n",
    "        pg_diam, pg_covs, _, _, pg_time = pareto_diam.plainGreedyDistanceScaled()\n",
    "        task_coverages['DistanceGreedy'] = list(align_to_diameter_arr(pg_diam, pg_covs))\n",
    "        task_runtimes['DistanceGreedy'].append(pg_time)\n",
    "        distance_size_counts.append(len(pg_diam))\n",
    "\n",
    "        # Top-K (distance-scaled) baseline\n",
    "        tk_diam, tk_covs, _, _, tk_time = pareto_diam.topKDegree()\n",
    "        task_coverages['TopDegree'] = list(align_to_diameter_arr(tk_diam, tk_covs))\n",
    "        task_runtimes['TopDegree'].append(tk_time)\n",
    "        topk_size_counts.append(len(tk_diam))\n",
    "\n",
    "        # Graph pruning baseline (already returns diameters)\n",
    "        pr_radii, pr_coverages, _, _, pr_time = pareto_diam.graphPruning()\n",
    "        pr_diameters = np.array(pr_radii, dtype=float)\n",
    "        pr_coverages = np.array(pr_coverages, dtype=float)\n",
    "        task_coverages['PruneGraph'] = list(align_to_diameter_arr(pr_diameters, pr_coverages))\n",
    "        task_runtimes['PruneGraph'].append(pr_time)\n",
    "        prune_size_counts.append(len(pr_diameters))\n",
    "\n",
    "        # convert per-task lists to numpy arrays and store in all_coverages\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(task_coverages[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(diameter_arr, dtype=float)\n",
    "            all_coverages[alg].append(arr)\n",
    "            runtimes = task_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "    # compute mean and std across tasks for each algorithm\n",
    "    mean_coverages = {}\n",
    "    std_coverages = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_coverages[alg])  # shape (numTasks, len(diameter_arr))\n",
    "        mean_coverages[alg] = np.mean(stacked, axis=0)\n",
    "        std_coverages[alg] = np.std(stacked, axis=0)\n",
    "\n",
    "    mean_cgreedy_size = float(np.mean(cgreedy_size_counts)) if len(cgreedy_size_counts) > 0 else 0.0\n",
    "    mean_prune_size = float(np.mean(prune_size_counts)) if len(prune_size_counts) > 0 else 0.0\n",
    "    mean_distance_size = float(np.mean(distance_size_counts)) if len(distance_size_counts) > 0 else 0.0\n",
    "    mean_topk_size = float(np.mean(topk_size_counts)) if len(topk_size_counts) > 0 else 0.0\n",
    "\n",
    "    mean_frontier_sizes = {\n",
    "        \"C-Greedy-Diameter\": mean_cgreedy_size,\n",
    "        \"PruneGraph\": mean_prune_size,\n",
    "        \"DistanceGreedy\": mean_distance_size,\n",
    "        \"TopDegree\": mean_topk_size,\n",
    "    }\n",
    "\n",
    "    # Plot mean coverage with shaded std band\n",
    "    tab10_colors = plt.get_cmap(\"tab10\").colors\n",
    "    color_map = {\n",
    "        \"C-Greedy-Diameter\": tab10_colors[2],\n",
    "        \"PruneGraph\": tab10_colors[3],\n",
    "        \"DistanceGreedy\": tab10_colors[1],\n",
    "        \"TopDegree\": tab10_colors[0],\n",
    "    }\n",
    "    marker_map = {\n",
    "        \"C-Greedy-Diameter\": \"X\",\n",
    "        \"PruneGraph\": \"o\",\n",
    "        \"DistanceGreedy\": \"s\",\n",
    "        \"TopDegree\": \"^\",\n",
    "    }\n",
    "    linestyle_map = {\n",
    "        \"C-Greedy-Diameter\": (0, (3, 2)),\n",
    "        \"PruneGraph\": (0, (4, 2)),\n",
    "        \"DistanceGreedy\": (0, (2, 2)),\n",
    "        \"TopDegree\": (0, (1, 1)),\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    label_map = {}\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    def pick_marker_indices(count):\n",
    "        if diameter_arr.size == 0 or count <= 0:\n",
    "            return np.array([], dtype=int)\n",
    "        count = int(max(2, min(diameter_arr.size, count)))\n",
    "        if count == 1:\n",
    "            return np.array([0], dtype=int)\n",
    "        step = (diameter_arr.size - 1) / float(count - 1)\n",
    "        max_offset = max(0.0, step - 1.0)\n",
    "        offset = rng.uniform(0.0, max_offset) if max_offset > 0 else 0.0\n",
    "        idx = np.round(offset + step * np.arange(count)).astype(int)\n",
    "        idx = np.clip(idx, 0, diameter_arr.size - 1)\n",
    "        idx = np.unique(idx)\n",
    "        if idx.size < 2:\n",
    "            idx = np.unique(np.round(np.linspace(0, diameter_arr.size - 1, count)).astype(int))\n",
    "        return idx\n",
    "\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_coverages[alg]\n",
    "        std = std_coverages[alg] * 0.5\n",
    "        is_pareto = alg == \"C-Greedy-Diameter\"\n",
    "        marker_size = 8 if is_pareto else 7\n",
    "        line_style = linestyle_map.get(alg, (0, (1, 1)))\n",
    "\n",
    "        color = color_map.get(alg, tab10_colors[i % len(tab10_colors)])\n",
    "        marker = marker_map.get(alg, 'o')\n",
    "        zorder = 4 if is_pareto else 3\n",
    "\n",
    "        label = rf\"\\texttt{{{alg}}}\"\n",
    "        label_map[alg] = label\n",
    "        ax.plot(diameter_arr, mean,\n",
    "                label=label,\n",
    "                color=color,\n",
    "                linestyle=line_style,\n",
    "                linewidth=1.8,\n",
    "                zorder=zorder)\n",
    "        marker_count = int(np.round(mean_frontier_sizes.get(alg, 0.0)))\n",
    "        marker_idx = pick_marker_indices(marker_count)\n",
    "        if marker_idx.size > 0:\n",
    "            ax.scatter(diameter_arr[marker_idx], mean[marker_idx],\n",
    "                       label=\"_nolegend_\",\n",
    "                       color=color,\n",
    "                       marker=marker,\n",
    "                       s=marker_size**2,\n",
    "                       edgecolor='k',\n",
    "                       linewidths=0.6,\n",
    "                       zorder=zorder + 1)\n",
    "        ax.fill_between(diameter_arr,\n",
    "                        np.clip(mean - std, 0, 1),\n",
    "                        np.clip(mean + std, 0, 1),\n",
    "                        color=color,\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel(r'Team diameter, $c_d$', fontsize=28)\n",
    "    ax.set_ylabel(r'Task coverage, $f$', fontsize=28)\n",
    "    ax.set_title(\"\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    # Legend handles (saved separately)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if handles:\n",
    "        from matplotlib.lines import Line2D\n",
    "        ordered_labels = [\n",
    "            label_map[\"C-Greedy-Diameter\"],\n",
    "            label_map[\"PruneGraph\"],\n",
    "            label_map[\"DistanceGreedy\"],\n",
    "            label_map[\"TopDegree\"],\n",
    "        ]\n",
    "        ordered_handles = []\n",
    "        for alg in [\"C-Greedy-Diameter\", \"PruneGraph\", \"DistanceGreedy\", \"TopDegree\"]:\n",
    "            is_pareto = alg == \"C-Greedy-Diameter\"\n",
    "            marker_size = 8 if is_pareto else 7\n",
    "            ordered_handles.append(\n",
    "                Line2D([0], [0],\n",
    "                       color=color_map.get(alg, \"k\"),\n",
    "                       linestyle=linestyle_map.get(alg, (0, (1, 1))),\n",
    "                       marker=marker_map.get(alg, 'o'),\n",
    "                       markersize=marker_size,\n",
    "                       markeredgewidth=1.1,\n",
    "                       markeredgecolor='k',\n",
    "                       linewidth=1.8)\n",
    "            )\n",
    "\n",
    "    # Save figure\n",
    "    from pathlib import Path\n",
    "    base_dir = Path.cwd().resolve().parents[1]\n",
    "    plots_dir = base_dir / \"plots\" / \"graph\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    safe_name = (dataset_name or \"dataset\").replace(\" \", \"_\")\n",
    "    out_path = plots_dir / f\"{safe_name}_graph.pdf\"\n",
    "    # fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "\n",
    "    # Save legend as separate PDF\n",
    "    if handles:\n",
    "        legend_out_path = plots_dir / \"graph_legend.pdf\"\n",
    "        if not legend_out_path.exists():\n",
    "            legend_fig = plt.figure(figsize=(8, 2))\n",
    "            legend_fig.legend(ordered_handles, ordered_labels, loc='center', ncol=2, fontsize=22, frameon=True)\n",
    "            legend_fig.savefig(legend_out_path, bbox_inches=\"tight\")\n",
    "            plt.close(legend_fig)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Runtime summary (latex row)\n",
    "    dataset_label = dataset_name or \"dataset\"\n",
    "    dataset_macro_map = {\n",
    "        \"Freelancer\": r\"\\freelancer\",\n",
    "        \"Bbsm\": r\"\\bibsonomy\",\n",
    "        \"IMDB-1\": r\"\\imdbone\",\n",
    "        \"IMDB-2\": r\"\\imdbtwo\",\n",
    "    }\n",
    "    dataset_macro = dataset_macro_map.get(dataset_label, rf\"\\\\dataset{{{dataset_label}}}\")\n",
    "    mean_cgreedy_rt = float(np.mean(all_runtimes['C-Greedy-Diameter'])) if len(all_runtimes['C-Greedy-Diameter']) > 0 else 0.0\n",
    "    mean_prune_rt = float(np.mean(all_runtimes['PruneGraph'])) if len(all_runtimes['PruneGraph']) > 0 else 0.0\n",
    "    mean_distance_rt = float(np.mean(all_runtimes['DistanceGreedy'])) if len(all_runtimes['DistanceGreedy']) > 0 else 0.0\n",
    "    mean_topk_rt = float(np.mean(all_runtimes['TopDegree'])) if len(all_runtimes['TopDegree']) > 0 else 0.0\n",
    "    runtime_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_rt:.3f} \"\n",
    "        f\"& {mean_prune_rt:.3f} \"\n",
    "        f\"& {mean_distance_rt:.3f} \"\n",
    "        f\"& {mean_topk_rt:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(runtime_row)\n",
    "\n",
    "    # Mean frontier sizes summary (latex row)\n",
    "    frontier_row = (\n",
    "        f\"{dataset_macro} \"\n",
    "        f\"& {mean_cgreedy_size:.3f} \"\n",
    "        f\"& {mean_prune_size:.3f} \"\n",
    "        f\"& {mean_distance_size:.3f} \"\n",
    "        f\"& {mean_topk_size:.3f} \\\\\\\\\"\n",
    "    )\n",
    "    logging.info(frontier_row)\n",
    "\n",
    "    summary_dir = plots_dir / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "    runtimes_path = summary_dir / \"runtimes.txt\"\n",
    "    frontier_path = summary_dir / \"frontier-size.txt\"\n",
    "    with open(runtimes_path, \"a\", encoding=\"utf-8\") as runtime_file:\n",
    "        runtime_file.write(runtime_row + \"\\n\")\n",
    "    with open(frontier_path, \"a\", encoding=\"utf-8\") as frontier_file:\n",
    "        frontier_file.write(frontier_row + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70d091",
   "metadata": {},
   "source": [
    "## Freelancer-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_graphmat_1 = expertCoordinationAdjacencyMatrix(fl_experts_1[:50], use_jaccard=True)\n",
    "findApproximateParetoSolutions(tasks_list=fl_tasks_1, experts_list=fl_experts_1, graphmat=fl_graphmat_1,\n",
    "                               sizeUniverse=50, numExperts=50, numTasks=20,\n",
    "                               maxDiameter=1.25 * np.max(fl_graphmat_1),\n",
    "                               dataset_name=\"Freelancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3115d",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_graphmat_1 = expertCoordinationAdjacencyMatrix(imdb_experts_1[:150])\n",
    "findApproximateParetoSolutions(tasks_list=imdb_tasks_1, experts_list=imdb_experts_1, graphmat=imdb_graphmat_1,\n",
    "                               sizeUniverse=24, numExperts=150, numTasks=30,\n",
    "                               maxDiameter=1.25 * np.max(imdb_graphmat_1),\n",
    "                               dataset_name=\"IMDB-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_graphmat_2 = expertCoordinationAdjacencyMatrix(imdb_experts_2[:300])\n",
    "findApproximateParetoSolutions(tasks_list=imdb_tasks_2, experts_list=imdb_experts_2, graphmat=imdb_graphmat_2,\n",
    "                               sizeUniverse=24, numExperts=300, numTasks=30,\n",
    "                               maxDiameter=1.25 * np.max(imdb_graphmat_2),\n",
    "                               dataset_name=\"IMDB-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2f6b7",
   "metadata": {},
   "source": [
    "## Bbsm-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f568a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbsm_graphmat_1 = expertCoordinationAdjacencyMatrix(bbsm_experts_1[:250])\n",
    "findApproximateParetoSolutions(tasks_list=bbsm_tasks_1, experts_list=bbsm_experts_1, graphmat=bbsm_graphmat_1,\n",
    "                               sizeUniverse=75, numExperts=250, numTasks=30,\n",
    "                               maxDiameter=1.25 * np.max(bbsm_graphmat_1),\n",
    "                               dataset_name=\"Bbsm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
