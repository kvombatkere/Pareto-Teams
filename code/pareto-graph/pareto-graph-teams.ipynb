{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoGraphTeams import *\n",
    "\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Enable LaTeX rendering if available (fallback to Matplotlib text otherwise)\n",
    "if shutil.which(\"latex\"):\n",
    "    mpl.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    })\n",
    "else:\n",
    "    mpl.rcParams.update({\"text.usetex\": False})\n",
    "\n",
    "# Import datasets\n",
    "# IMDB\n",
    "imdb_experts_1, imdb_tasks_1, imdb_costs_1, imdb_graphmat_1 = import_pickled_datasets('imdb', 1)\n",
    "imdb_experts_2, imdb_tasks_2, imdb_costs_2, imdb_graphmat_2 = import_pickled_datasets('imdb', 2)\n",
    "# imdb_experts_3, imdb_tasks_3, imdb_costs_3, imdb_graphmat_3 = import_pickled_datasets('imdb', 3)\n",
    "\n",
    "# Bibsonomy\n",
    "bbsm_experts_1, bbsm_tasks_1, bbsm_costs_1, bbsm_graphmat_1 = import_pickled_datasets('bbsm', 1)\n",
    "# bbsm_experts_2, bbsm_tasks_2, bbsm_costs_2, bbsm_graphmat_2 = import_pickled_datasets('bbsm', 2)\n",
    "\n",
    "# Freelancer\n",
    "fl_experts_1, fl_tasks_1, fl_costs_1, fl_graphmat_1 = import_pickled_datasets('freelancer', 1)\n",
    "# fl_experts_2, fl_tasks_2, fl_costs_2, fl_graphmat_2 = import_pickled_datasets('freelancer', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6dd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize distance matrices (symmetric, zero diagonal)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def _randomize_graphmat(mat):\n",
    "    n = mat.shape[0]\n",
    "    rand = rng.uniform(0.1, 1.0, size=(n, n))\n",
    "    rand = (rand + rand.T) / 2.0\n",
    "    np.fill_diagonal(rand, 0.0)\n",
    "    return rand\n",
    "\n",
    "imdb_graphmat_1 = _randomize_graphmat(imdb_graphmat_1)\n",
    "imdb_graphmat_2 = _randomize_graphmat(imdb_graphmat_2)\n",
    "bbsm_graphmat_1 = _randomize_graphmat(bbsm_graphmat_1)\n",
    "fl_graphmat_1 = _randomize_graphmat(fl_graphmat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_graphmat_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a928fa",
   "metadata": {},
   "source": [
    "### Average Plotting across Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6df044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findApproximateParetoSolutions(tasks_list, experts_list, graphmat,\n",
    "                                   sizeUniverse, numExperts, numTasks, maxDiameter,\n",
    "                                   dataset_name=None, start_index=0):\n",
    "    '''\n",
    "    Run graph-diameter algorithm over multiple tasks, aggregate results, and plot mean +/- std.\n",
    "    '''\n",
    "    # Diameter grid (same for all tasks)\n",
    "    num_steps, min_diameter = 15, 0.0\n",
    "    diameter_arr = np.linspace(min_diameter, maxDiameter, num_steps)\n",
    "\n",
    "    algo_names = [\"ParetoGreedy-Diameter\", \"PlainGreedy-Scaled\", \"TopK-Scaled\", \"GraphPruning\"]\n",
    "\n",
    "    def align_to_diameter_arr(diameters, covs):\n",
    "        if len(diameters) == 0 or len(covs) == 0:\n",
    "            return np.zeros_like(diameter_arr, dtype=float)\n",
    "        diameters = np.array(diameters, dtype=float)\n",
    "        covs = np.array(covs, dtype=float)\n",
    "\n",
    "        # Ensure matching lengths\n",
    "        min_len = min(len(diameters), len(covs))\n",
    "        diameters = diameters[:min_len]\n",
    "        covs = covs[:min_len]\n",
    "\n",
    "        # Aggregate duplicate diameters by taking max coverage\n",
    "        agg = {}\n",
    "        for d, c in zip(diameters, covs):\n",
    "            if d in agg:\n",
    "                agg[d] = max(agg[d], c)\n",
    "            else:\n",
    "                agg[d] = c\n",
    "        if len(agg) == 0:\n",
    "            return np.zeros_like(diameter_arr, dtype=float)\n",
    "        diameters_sorted = np.array(sorted(agg.keys()), dtype=float)\n",
    "        covs_sorted = np.array([agg[d] for d in diameters_sorted], dtype=float)\n",
    "\n",
    "        return np.interp(diameter_arr, diameters_sorted, covs_sorted, left=covs_sorted[0], right=covs_sorted[-1])\n",
    "\n",
    "    # containers across tasks\n",
    "    all_coverages = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "    pareto_diams_all = []\n",
    "    pareto_points_counts = []\n",
    "\n",
    "    # iterate tasks\n",
    "    for task_index in range(start_index, start_index + numTasks):\n",
    "        # per-task containers\n",
    "        task_coverages = {alg: [] for alg in algo_names}\n",
    "        task_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # Initialize Pareto teams object\n",
    "        pareto_diam = paretoGraph(task=tasks_list[task_index],\n",
    "                                  n_experts=experts_list[:numExperts],\n",
    "                                  pairwise_costs=graphmat[:numExperts, :numExperts],\n",
    "                                  size_univ=sizeUniverse,\n",
    "                                  budget=1)\n",
    "\n",
    "        diameters, best_coverages, _, _, runTime = pareto_diam.ParetoGreedyDiameter()\n",
    "        diameters = np.array(diameters, dtype=float)\n",
    "\n",
    "        # Interpolate to shared diameter grid\n",
    "        task_coverages['ParetoGreedy-Diameter'] = list(align_to_diameter_arr(diameters, best_coverages))\n",
    "        task_runtimes['ParetoGreedy-Diameter'].append(runTime)\n",
    "        pareto_diams_all.extend(diameters)\n",
    "        pareto_points_counts.append(len(diameters))\n",
    "\n",
    "        # Plain Greedy (distance-scaled) baseline\n",
    "        pg_diam, pg_covs, _, _, pg_time = pareto_diam.plainGreedyDistanceScaled()\n",
    "        task_coverages['PlainGreedy-Scaled'] = list(align_to_diameter_arr(pg_diam, pg_covs))\n",
    "        task_runtimes['PlainGreedy-Scaled'].append(pg_time)\n",
    "\n",
    "        # Top-K (distance-scaled) baseline\n",
    "        tk_diam, tk_covs, _, _, tk_time = pareto_diam.topKDistanceScaled()\n",
    "        task_coverages['TopK-Scaled'] = list(align_to_diameter_arr(tk_diam, tk_covs))\n",
    "        task_runtimes['TopK-Scaled'].append(tk_time)\n",
    "\n",
    "        # Graph pruning baseline (already returns diameters)\n",
    "        pr_radii, pr_coverages, _, _, pr_time = pareto_diam.graphPruning()\n",
    "        pr_diameters = np.array(pr_radii, dtype=float)\n",
    "        task_coverages['GraphPruning'] = list(align_to_diameter_arr(pr_diameters, pr_coverages))\n",
    "        task_runtimes['GraphPruning'].append(pr_time)\n",
    "\n",
    "        # convert per-task lists to numpy arrays and store in all_coverages\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(task_coverages[alg], dtype=float)\n",
    "            if arr.size == 0:\n",
    "                arr = np.zeros_like(diameter_arr, dtype=float)\n",
    "            all_coverages[alg].append(arr)\n",
    "            runtimes = task_runtimes.get(alg, [])\n",
    "            total_runtime = float(np.nansum(np.array(runtimes, dtype=float))) if len(runtimes) > 0 else 0.0\n",
    "            all_runtimes[alg].append(total_runtime)\n",
    "\n",
    "    # compute mean and std across tasks for each algorithm\n",
    "    mean_coverages = {}\n",
    "    std_coverages = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_coverages[alg])  # shape (numTasks, len(diameter_arr))\n",
    "        mean_coverages[alg] = np.mean(stacked, axis=0)\n",
    "        std_coverages[alg] = np.std(stacked, axis=0)*0.5\n",
    "\n",
    "    mean_pareto_points = int(np.round(np.mean(pareto_points_counts))) if len(pareto_points_counts) > 0 else 0\n",
    "    if mean_pareto_points < 1:\n",
    "        mean_pareto_points = 1\n",
    "\n",
    "    # Plot mean coverage with shaded std band\n",
    "    colors = plt.get_cmap(\"tab10\").colors\n",
    "    linestyles = ['-', '--', '-.', ':', (0, (3,1,1,1))]\n",
    "    markers = ['o', 's', '^', 'v', 'D']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5.5))\n",
    "    label_map = {}\n",
    "    pareto_legend_handle = None\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_coverages[alg]\n",
    "        std = std_coverages[alg]*0.5\n",
    "        is_pareto = alg == \"ParetoGreedy-Diameter\"\n",
    "        marker_size = 7 if is_pareto else 6\n",
    "        line_style = '-' if is_pareto else ':'\n",
    "\n",
    "        if is_pareto:\n",
    "            color = colors[3]\n",
    "        else:\n",
    "            color = colors[(i + 1) % len(colors)]\n",
    "        marker = \"D\" if is_pareto else markers[i % len(markers)]\n",
    "        zorder = 4 if is_pareto else 3\n",
    "\n",
    "        label = rf\"\\texttt{{{alg}}} (ours)\" if is_pareto else rf\"\\texttt{{{alg}}}\"\n",
    "        label_map[alg] = label\n",
    "        if is_pareto:\n",
    "            ax.plot(diameter_arr, mean,\n",
    "                    label=\"_nolegend_\",\n",
    "                    color=color,\n",
    "                    linestyle=line_style,\n",
    "                    linewidth=1.8,\n",
    "                    zorder=zorder)\n",
    "            pareto_diams_unique = np.unique(np.array(pareto_diams_all, dtype=float))\n",
    "            pareto_diams_unique = pareto_diams_unique[(pareto_diams_unique >= diameter_arr.min()) & (pareto_diams_unique <= diameter_arr.max())]\n",
    "            if pareto_diams_unique.size > 0:\n",
    "                keep_count = max(1, min(mean_pareto_points, pareto_diams_unique.size))\n",
    "                keep_idx = np.linspace(0, pareto_diams_unique.size - 1, keep_count).astype(int)\n",
    "                pareto_diams_unique = pareto_diams_unique[keep_idx]\n",
    "            pareto_mean_vals = np.interp(pareto_diams_unique, diameter_arr, mean)\n",
    "            ax.scatter(pareto_diams_unique, pareto_mean_vals,\n",
    "                       label=\"_nolegend_\",\n",
    "                       color=color,\n",
    "                       marker=marker,\n",
    "                       s=marker_size**2,\n",
    "                       edgecolor='k',\n",
    "                       linewidths=0.6,\n",
    "                       zorder=zorder + 1)\n",
    "            from matplotlib.lines import Line2D\n",
    "            pareto_legend_handle = Line2D([0], [0],\n",
    "                                          color=color,\n",
    "                                          linestyle=line_style,\n",
    "                                          marker=marker,\n",
    "                                          markersize=marker_size,\n",
    "                                          markeredgewidth=1.1,\n",
    "                                          markeredgecolor='k',\n",
    "                                          linewidth=1.8)\n",
    "        else:\n",
    "            ax.plot(diameter_arr, mean,\n",
    "                    label=label,\n",
    "                    color=color,\n",
    "                    linestyle=line_style,\n",
    "                    marker=marker,\n",
    "                    markersize=marker_size,\n",
    "                    markeredgewidth=1.1,\n",
    "                    markeredgecolor='k',\n",
    "                    linewidth=1.8,\n",
    "                    zorder=zorder)\n",
    "        ax.fill_between(diameter_arr,\n",
    "                        np.clip(mean - std, 0, 1),\n",
    "                        np.clip(mean + std, 0, 1),\n",
    "                        color=color,\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel(r'Team diameter ($d$)', fontsize=28)\n",
    "    ax.set_ylabel(r'Mean task coverage ($\\bar{f}$)', fontsize=28)\n",
    "    ax.set_title(\"\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='both', labelsize=24)\n",
    "\n",
    "    # Legend handles (saved separately)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if handles:\n",
    "        handle_map = dict(zip(labels, handles))\n",
    "        pareto_label = label_map.get(\"ParetoGreedy-Diameter\")\n",
    "        if pareto_label and pareto_legend_handle is not None:\n",
    "            handle_map[pareto_label] = pareto_legend_handle\n",
    "        ordered_labels = []\n",
    "        if pareto_label:\n",
    "            ordered_labels.append(pareto_label)\n",
    "        ordered_labels.extend([label_map[alg] for alg in algo_names if alg != \"ParetoGreedy-Diameter\"])\n",
    "        ordered_handles = [handle_map[l] for l in ordered_labels if l in handle_map]\n",
    "\n",
    "    # Save figure\n",
    "    from pathlib import Path\n",
    "    base_dir = Path.cwd().resolve().parents[1]\n",
    "    plots_dir = base_dir / \"plots\" / \"graph\"\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    safe_name = (dataset_name or \"dataset\").replace(\" \", \"_\")\n",
    "    out_path = plots_dir / f\"{safe_name}_graph.pdf\"\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "\n",
    "    # Save legend as separate PDF\n",
    "    if handles:\n",
    "        legend_out_path = plots_dir / \"graph_legend.pdf\"\n",
    "        if not legend_out_path.exists():\n",
    "            legend_fig = plt.figure(figsize=(8, 2))\n",
    "            legend_fig.legend(ordered_handles, ordered_labels, loc='center', ncol=2, fontsize=22, frameon=True)\n",
    "            legend_fig.savefig(legend_out_path, bbox_inches=\"tight\")\n",
    "            plt.close(legend_fig)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Runtime summary (mean ± std)\n",
    "    runtime_lines = [\"Runtime summary (mean ± std, seconds):\"]\n",
    "    for alg in algo_names:\n",
    "        mean_rt = float(np.mean(all_runtimes[alg])) if len(all_runtimes[alg]) > 0 else 0.0\n",
    "        std_rt = float(np.std(all_runtimes[alg])) if len(all_runtimes[alg]) > 0 else 0.0\n",
    "        runtime_lines.append(f\"  - {alg}: {mean_rt:.3f} ± {std_rt:.3f}\")\n",
    "    logging.info(\"\\n\".join(runtime_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70d091",
   "metadata": {},
   "source": [
    "## Freelancer-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=fl_tasks_1, experts_list=fl_experts_1, graphmat=fl_graphmat_1,\n",
    "                               sizeUniverse=50, numExperts=50, numTasks=10,\n",
    "                               maxDiameter=2 * np.max(fl_graphmat_1[:50, :50]),\n",
    "                               dataset_name=\"Freelancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3115d",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=imdb_tasks_1, experts_list=imdb_experts_1, graphmat=imdb_graphmat_1,\n",
    "                               sizeUniverse=24, numExperts=150, numTasks=10,\n",
    "                               maxDiameter=2 * np.max(imdb_graphmat_1[:150, :150]),\n",
    "                               dataset_name=\"IMDB-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=imdb_tasks_2, experts_list=imdb_experts_2, graphmat=imdb_graphmat_2,\n",
    "                               sizeUniverse=24, numExperts=150, numTasks=20,\n",
    "                               maxDiameter=2 * np.max(imdb_graphmat_2[:150, :150]),\n",
    "                               dataset_name=\"IMDB-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2f6b7",
   "metadata": {},
   "source": [
    "## Bbsm-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f568a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "findApproximateParetoSolutions(tasks_list=bbsm_tasks_1, experts_list=bbsm_experts_1, graphmat=bbsm_graphmat_1,\n",
    "                               sizeUniverse=75, numExperts=150, numTasks=20,\n",
    "                               maxDiameter=2 * np.max(bbsm_graphmat_1[:150, :150]),\n",
    "                               dataset_name=\"Bbsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254434c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
