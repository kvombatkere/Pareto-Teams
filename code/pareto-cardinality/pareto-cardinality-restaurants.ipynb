{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paretoCardinalityRestaurants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to sample numItems from the dataset\n",
    "def sample_dataset(simMatrix, item_ids, numItems):\n",
    "    '''\n",
    "    Samples a subset of items from the dataset.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.\n",
    "        numItems (int): Number of items to sample.\n",
    "    Returns:\n",
    "        sampled_simMatrix (np.ndarray): Sampled similarity matrix of shape (numItems, numItems).\n",
    "        sampled_item_ids (list): List of sampled item IDs of length numItems.\n",
    "    '''\n",
    "    sampled_indices = np.random.choice(len(item_ids), size=numItems, replace=False)\n",
    "    sampled_simMatrix = simMatrix[np.ix_(sampled_indices, sampled_indices)]\n",
    "    sampled_item_ids = [item_ids[i] for i in sampled_indices]\n",
    "\n",
    "    return sampled_simMatrix, sampled_item_ids\n",
    "\n",
    "\n",
    "def findApproximateParetoSolutions(simMatrix, item_ids, sample_size, numSamples, k_max):\n",
    "    '''\n",
    "    Run algorithms over multiple random samples of the dataset, aggregate results, and plot mean +/- std.\n",
    "    Args:\n",
    "        simMatrix (np.ndarray): Similarity matrix of shape (N, N).\n",
    "        item_ids (list): List of item IDs of length N.      \n",
    "        sample_size (int): Number of items to sample from the dataset.\n",
    "        numSamples (int): Number of random samples to run.\n",
    "        k_max (int): Maximum cardinality.\n",
    "    '''\n",
    "    algo_names = [\"ParetoGreedy\", \"TopK\", \"Random\"]\n",
    "\n",
    "    # containers across samples\n",
    "    all_objectives = {alg: [] for alg in algo_names}\n",
    "    all_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "    print(f\"Starting processing {numSamples} samples with sample size {sample_size} and k_max {k_max}\")\n",
    "\n",
    "    # iterate samples\n",
    "    for sample_index in range(numSamples):\n",
    "        print(f\"Processing sample {sample_index + 1}/{numSamples}\")\n",
    "        \n",
    "        # per-sample containers\n",
    "        sample_objectives = {alg: [] for alg in algo_names}\n",
    "        sample_runtimes = {alg: [] for alg in algo_names}\n",
    "\n",
    "        # sample the dataset\n",
    "        sampled_simMatrix, sampled_item_ids = sample_dataset(simMatrix, item_ids, sample_size)\n",
    "\n",
    "        # Initialize Pareto cardinality restaurants object\n",
    "        paretoCard = paretoCardinalityRestaurants(n_items=sampled_item_ids,\n",
    "                                                  simMatrix=sampled_simMatrix,\n",
    "                                                  k_max=k_max)\n",
    "\n",
    "        # Greedy Cardinality\n",
    "        _, _, _, runTime = paretoCard.greedyCardinality()\n",
    "        objectives = []\n",
    "        current_objective = 0\n",
    "        for k in range(1, k_max + 1):\n",
    "            if k in paretoCard.kSolDict:\n",
    "                current_objective = paretoCard.kSolDict[k]['Coverage']\n",
    "            objectives.append(current_objective)\n",
    "        sample_objectives['ParetoGreedy'] = objectives\n",
    "        sample_runtimes['ParetoGreedy'] = runTime\n",
    "\n",
    "        # Top K\n",
    "        paretoCard2 = paretoCardinalityRestaurants(n_items=sampled_item_ids,\n",
    "                                                   simMatrix=sampled_simMatrix,\n",
    "                                                   k_max=k_max)\n",
    "        _, _, _, runTime = paretoCard2.top_k()\n",
    "        objectives = [paretoCard2.kSolDict[k]['Coverage'] for k in range(1, k_max + 1)]\n",
    "        sample_objectives['TopK'] = objectives\n",
    "        sample_runtimes['TopK'] = runTime\n",
    "\n",
    "        # Random\n",
    "        paretoCard3 = paretoCardinalityRestaurants(n_items=sampled_item_ids,\n",
    "                                                   simMatrix=sampled_simMatrix,\n",
    "                                                   k_max=k_max)\n",
    "        _, _, _, runTime = paretoCard3.random_selection()\n",
    "        objectives = [paretoCard3.kSolDict[k]['Coverage'] for k in range(1, k_max + 1)]\n",
    "        sample_objectives['Random'] = objectives\n",
    "        sample_runtimes['Random'] = runTime\n",
    "\n",
    "        # convert per-sample lists to numpy arrays and store\n",
    "        for alg in algo_names:\n",
    "            arr = np.array(sample_objectives[alg], dtype=float)\n",
    "            all_objectives[alg].append(arr)\n",
    "            all_runtimes[alg].append(sample_runtimes[alg])\n",
    "\n",
    "    # compute mean and std across samples for each algorithm\n",
    "    mean_objectives = {}\n",
    "    std_objectives = {}\n",
    "    for alg in algo_names:\n",
    "        stacked = np.vstack(all_objectives[alg])  # shape (numSamples, k_max)\n",
    "        mean_objectives[alg] = np.mean(stacked, axis=0)\n",
    "        std_objectives[alg] = np.std(stacked, axis=0) * 0.5\n",
    "\n",
    "    # Plot mean objective with shaded std band\n",
    "    colors = cm.magma(np.linspace(0.01, 0.8, len(algo_names)))\n",
    "    linestyles = ['-', '--', ':']\n",
    "    markers = ['o', 's', '^']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    for i, alg in enumerate(algo_names):\n",
    "        mean = mean_objectives[alg]\n",
    "        std = std_objectives[alg]\n",
    "\n",
    "        ax.plot(range(1, k_max + 1), mean,\n",
    "                label=alg,\n",
    "                color=colors[i],\n",
    "                linestyle=linestyles[i],\n",
    "                marker=markers[i],\n",
    "                markersize=5,\n",
    "                markeredgewidth=0.8,\n",
    "                markeredgecolor='k',\n",
    "                linewidth=1.2,\n",
    "                zorder=3)\n",
    "        ax.fill_between(range(1, k_max + 1),\n",
    "                        np.clip(mean - std, 0, None),\n",
    "                        mean + std,\n",
    "                        color=colors[i],\n",
    "                        alpha=0.18,\n",
    "                        zorder=2)\n",
    "\n",
    "    ax.set_xlabel('Cardinality (k)')\n",
    "    ax.set_ylabel('Mean Objective')\n",
    "    ax.set_title('Mean Objective across samples (shaded = ±0.5 std)')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot total runtime per algorithm with mean +/- std bars\n",
    "    means_rt = [np.mean(all_runtimes[alg]) for alg in algo_names]\n",
    "    stds_rt = [np.std(all_runtimes[alg]) for alg in algo_names]\n",
    "    x = np.arange(len(algo_names))\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 3))\n",
    "    bars = ax2.bar(x, means_rt, yerr=stds_rt, capsize=5, color=[colors[i] for i in range(len(algo_names))])\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(algo_names, rotation=30, ha='right', fontsize=8)\n",
    "    ax2.set_ylabel('Total Runtime (s)')\n",
    "    ax2.set_title('Mean Total Runtime per Algorithm (±std)')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a928fa",
   "metadata": {},
   "source": [
    "### Yelp Phoenix Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Yelp Phoenix dataset\n",
    "data_path = '../../datasets/pickled_data/yelp/yelp_phoenix_'\n",
    "    \n",
    "#Import pickled data\n",
    "with open(data_path + 'ids.pkl', \"rb\") as fp:\n",
    "    phoenix_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'sim.pkl', \"rb\") as fp:\n",
    "    phoenix_simMatrix = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust parameters as needed\n",
    "sample_size = 500\n",
    "numSamples = 20  #number of random samples\n",
    "kmax = 50\n",
    "\n",
    "findApproximateParetoSolutions(phoenix_simMatrix, phoenix_ids, sample_size, numSamples, kmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8178f54",
   "metadata": {},
   "source": [
    "### Yelp Vegas Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Yelp Vegas dataset\n",
    "data_path = '../../datasets/pickled_data/yelp/yelp_vegas_'\n",
    "    \n",
    "#Import pickled data\n",
    "with open(data_path + 'ids.pkl', \"rb\") as fp:\n",
    "    vegas_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_path + 'sim.pkl', \"rb\") as fp:\n",
    "    vegas_simMatrix = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724134e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust parameters as needed\n",
    "sample_size = 500\n",
    "numSamples = 20  #number of random samples\n",
    "kmax = 50\n",
    "\n",
    "findApproximateParetoSolutions(vegas_simMatrix, vegas_ids, sample_size, numSamples, kmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pareto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
